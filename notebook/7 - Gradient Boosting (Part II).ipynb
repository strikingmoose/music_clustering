{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting (Part II)\n",
    "## Troubleshooting Our Model\n",
    "So we saw that our first GBT approach in the last post was, to quote myself, a \"steaming pile of hot garbage\". In reality, that's probably and understatement because it's barely even a model. I could've gotten the results with literally no model and straight guesses. Disappointing to say the least.\n",
    "\n",
    "![](http://i.imgur.com/8zXjYXy.gif)\n",
    "\n",
    "Of course, now, the question is... Why? Why is this model so bad? There are so many things that could have gone wrong:\n",
    "1. Did I misclassify some songs in my library in theory?\n",
    "2. Did I misclassify some songs in my library in practice (i.e. accidentally classified a Rock song as R&B)?\n",
    "3. Is my feature extraction method appropriate (i.e. MFCCs)?\n",
    "4. Is gradient boosting appropriate for this application?\n",
    "5. Did I take enough gradient boosting iterations to really allow the model settle and optimize?\n",
    "\n",
    "So many questions. So little answers... The solutions to the above would be\n",
    "1. Re-think my classifications of genres and re-classify my entire library, this may include adding new genres, taking away existing genres, or switching songs from one genre to another.\n",
    "2. Thoroughly check all 4000 songs again for mistakes.\n",
    "3. Do another week of research regarding feature extraction methods for music.\n",
    "4. Try other models (neural network).\n",
    "5. Leave the model running overnight / get a faster CPU (AWS?).\n",
    "\n",
    "I'm going to try to tweak \\#1 purely on the basis that it's probably the least time consuming solution... a quick win _**IF**_ it works, and not too big of a sunk cost if it doesn't. I'm actually going to approach \\#1 in a way that should mitigate the effects of \\#2, \\#3, and \\#5 as well. I'm going to take two very distinct genres of equal population and try to run the model only on those 2. Let's take Rock and Easy Listening for now because they should be quite different (the Radioheads and Portisheads come to mind that could _**kind of**_ cross over semetimes, but for the most part they're quite different).\n",
    "\n",
    "With only these two genres, we're dealing with less than 10% of our original data set. We're also taking the more ambiguous genres out (e.g. Dance, R&B, Hip Hop and Jazz have more overlap than Rock and Easy Listening). With this, I'll get more confidence in whether or not MFCCs do the job as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Enable plots in the notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Seaborn makes our plots prettier\n",
    "import seaborn\n",
    "seaborn.set(style = 'ticks')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the dataset we generated in the previous post\n",
    "my_itunes_data = pd.read_csv(\n",
    "    '../features.csv', \n",
    "    header = None,\n",
    "    names = [\n",
    "        'song_id',\n",
    "        'title',\n",
    "        'artist',\n",
    "        'genre',\n",
    "        'mfcc_1',\n",
    "        'mfcc_2',\n",
    "        'mfcc_3',\n",
    "        'mfcc_4',\n",
    "        'mfcc_5',\n",
    "        'mfcc_6',\n",
    "        'mfcc_7',\n",
    "        'mfcc_8',\n",
    "        'mfcc_9',\n",
    "        'mfcc_10'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "song_id      int64\n",
       "title       object\n",
       "artist      object\n",
       "genre       object\n",
       "mfcc_1     float64\n",
       "mfcc_2     float64\n",
       "mfcc_3     float64\n",
       "mfcc_4     float64\n",
       "mfcc_5     float64\n",
       "mfcc_6     float64\n",
       "mfcc_7     float64\n",
       "mfcc_8     float64\n",
       "mfcc_9     float64\n",
       "mfcc_10    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that the data imported properly\n",
    "my_itunes_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2470678"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check number of rows in the data set\n",
    "my_itunes_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3825"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of songs\n",
    "my_itunes_data['song_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove any training samples with \"Prince\" as artist\n",
    "my_itunes_data = my_itunes_data[(my_itunes_data['genre'].isin(['Rock', 'Easy Listening']))]\n",
    "\n",
    "# Check the number of songs\n",
    "my_itunes_data['song_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're dealing with wayyyyy less songs now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x12247a2d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqkAAAIxCAYAAABuEyHpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAIABJREFUeJzt3X90V/Wd5/FXEkigIKtiAspAq7a7YqpAEUZtsVu03a2I\nnQEtddrpYFvZIon9dTqDU0fH+gOrnY6O8SetMsXObBRaZzr+mGqd3faoLQoCLmhrsJ2CShJqRUT0\nCyH7h2u6GYglmCbX5PE4p+c0n8/N975zDs159n7v/aasvb29PQAAUCDlfT0AAAD8RyIVAIDCEakA\nABSOSAUAoHBEKgAAhSNSAQAoHJEKAEDhiFToppaWllx77bVpaWnp61EAeoTfaxSRSIVuam1tTUND\nQ1pbW/t6FIAe4fcaRbTfkVoqlTJz5sw88sgjHWvPPfdczjnnnEycODH/7b/9t9xzzz2dvuehhx7K\nzJkzM3HixMydOzcbN27c/8kBAOi39itSS6VSvvjFL6apqaljra2tLfPmzUtVVVXuvPPOfOpTn8qX\nv/zljmOee+65LFiwILNnz87y5ctz0EEHZcGCBT3zUwAA0K8M6u43bNiwIV/60pf2WP9f/+t/pbm5\nOY2NjXnb296Wd7zjHfnxj3+cxx57LO985ztzxx135JhjjsncuXOTJIsWLcp73/vePPLII5kyZcqb\n/kEAAOg/un0ldcWKFTnhhBPS2NiY9vb2jvVHHnkkxx9/fN72trd1rDU0NOTMM89MkqxZs6ZTjA4Z\nMiRHH310HnvssTczPwAA/VC3r6SeddZZe13fuHFj/uAP/iB/8zd/k3/6p3/KwQcfnLq6upxyyilJ\nXntysKamptP3HHLIIWlubt6PsQEA6M+6Haldefnll/Pd7343p556am666ab85Cc/yec+97ncfvvt\nqa2tzSuvvJLKyspO31NZWZlSqbTP52hpaenyycNPfOIT2bVr1x4hDD1t586dSZL58+dn8ODBfTwN\nwJvn9xq9paWlJYMHD87SpUu7PKa6ujo1NTU9F6kVFRU56KCDcvHFFydJxo8fn0cffTSNjY356le/\nmqqqqj2CtFQqZcSIEft8jsbGxjQ0NHS5X1ZWtn/DQzeUl5dnxIgRKS/3CW5A/+D3Gr2lra0tbW1t\nmTVrVpfH1NXVpb6+vucitbq6eo9/3Icffnh+/vOfJ0lGjRq1x1XQLVu2ZPz48ft8jjlz5mT69Ol7\n3Zs/f37Ky8vzwx/+sJuTAwDQG04++eS0tbXluuuu6/KY6urqJD34dv/EiRNz4403pr29veOK5oYN\nGzJmzJgkyYQJE7Jq1aqO43fs2JH169envr5+n89RU1PT5dv53p4AACi+ioqK1NbW/s7jeuy6/owZ\nM7J79+789V//dX71q1/lO9/5Tn784x9nzpw5SZLZs2dn1apVWbx4cZqamnL++edn3LhxmTp1ak+N\nAABAP/GmIvX/vwd0+PDhueWWW/L0009n5syZue2223L11VfnqKOOSpKMGTMm1157bZYvX54zzzwz\n27Zte8P7SwEAGLjK2v//Dzt9Czv55JOTxD2pAAAF1Z1e8xgfAACFI1IBACgckQoAQOGIVAAACkek\nAgBQOCIVAIDCEakAABSOSAUAoHBEKgAAhSNSAQAoHJEKAEDhiFQAAApHpAIAUDgiFQCAwhGpAAAU\njkgFAKBwRCoAAIUjUgEAKByRCgBA4YhUAAAKR6QCAFA4IhUAgMIRqQAAFI5IBQCgcEQqAACFI1IB\nACgckQoAQOGIVAAACkekAgBQOCIVAIDCEakAABSOSAUAoHBEKgAAhSNSAQAoHJEKAEDhiFQAAApH\npAIAUDgiFQCAwhGpAAAUjkgFAKBwRCoAAIWz35FaKpUyc+bMPPLII3vsvfTSSznppJNy5513dlp/\n6KGHMnPmzEycODFz587Nxo0b9/f0AAD0Y/sVqaVSKV/84hfT1NS01/0rr7wyra2tndaee+65LFiw\nILNnz87y5ctz0EEHZcGCBftzegAA+rluR+qGDRvy0Y9+NJs2bdrr/qOPPpqf/vSnOeSQQzqt33HH\nHTnmmGMyd+7cHHnkkVm0aFGeeeaZvV6JBQBgYBvU3W9YsWJFTjjhhHz+85/PhAkTOu2VSqVceOGF\nueiii3LBBRd02luzZk2mTJnS8fWQIUNy9NFH57HHHuu0Tu8qlUpZs2ZNX4/BADFhwoRUVlb29RgA\nvAV0O1LPOuusLvduvPHG1NbW5sQTT9xjr6WlJTU1NZ3WDjnkkDQ3N3d3BHrQmjVrcs5fLc0BI8f1\n9Sj0c9t+/assviT+TykA+6TbkdqVpqam3H777fnnf/7nve6/8sore1xBqaysTKlU6qkR2E8HjByX\nA0e/q6/HAADo0GOR+ld/9Vc577zzcvDBB+91v6qqao8gLZVKGTFixD6fo6WlZY8Hsl63c+fOlJf7\nRC0AgCJra2vLunXrutyvrq5OTU1Nz0Tqs88+m8ceeyw/+9nPsmjRoiSvXTm98MILc/fdd+fmm2/O\nqFGj9gjMLVu2ZPz48ft8nsbGxjQ0NHS5353gBQCg923fvj2zZs3qcr+uri719fU9E6mjR4/Offfd\n12ntE5/4RD75yU9m5syZSV57YGLVqlUd+zt27Mj69etTX1+/z+eZM2dOpk+fvte9+fPnu5IKAFBw\nw4YNy5IlS7rcr66uTtJDb/eXl5dn7NixndYqKioycuTIjoelZs+enVtuuSWLFy/OBz7wgTQ0NGTc\nuHGZOnXqPp+npqZmj4evXjd48OD9/wEAAOgVFRUVqa2t/Z3HvalLj2VlZfu8N2bMmFx77bVZvnx5\nzjzzzGzbtu0N37oHAGDgelNXUp944oku9374wx/usTZt2rTce++9b+aUAAAMAG7iBACgcEQqAACF\nI1IBACgckQoAQOGIVAAACkekAgBQOCIVAIDCEakAABSOSAUAoHBEKgAAhSNSAQAoHJEKAEDhiFQA\nAApHpAIAUDgiFQCAwhGpAAAUjkgFAKBwRCoAAIUjUgEAKByRCgBA4YhUAAAKR6QCAFA4IhUAgMIR\nqQAAFI5IBQCgcEQqAACFI1IBACgckQoAQOGIVAAACkekAgBQOCIVAIDCEakAABSOSAUAoHBEKgAA\nhSNSAQAoHJEKAEDhiFQAAApHpAIAUDgiFQCAwhGpAAAUjkgFAKBwRCoAAIWz35FaKpUyc+bMPPLI\nIx1rq1evzsc+9rFMmjQpH/7wh3PHHXd0+p6HHnooM2fOzMSJEzN37txs3Lhx/ycHAKDf2q9ILZVK\n+eIXv5impqaOtS1btmTevHk5/vjj80//9E+pr6/PpZdemv/9v/93kuTZZ5/NggULMnv27CxfvjwH\nHXRQFixY0DM/BQAA/Uq3I3XDhg356Ec/mk2bNnVav//++1NdXZ3Pf/7zGTduXE499dR85CMfyb/8\ny78kSe64444cc8wxmTt3bo488sgsWrQozzzzTKcrsQAAkOxHpK5YsSInnHBCGhsb097e3rF+0kkn\nZdGiRXscv23btiTJ2rVrM2XKlI71IUOG5Oijj85jjz22P3MDANCPDeruN5x11ll7XT/ssMNy2GGH\ndXz961//OnfffXfOO++8JElLS0tqamo6fc8hhxyS5ubm7o4AAEA/1+1I3Revvvpq6uvrU1NTkzlz\n5iRJXnnllVRWVnY6rrKyMqVSaZ9ft6WlJa2trXvd27lzZ8rLfVgBAECRtbW1Zd26dV3uV1dXp6am\npucj9eWXX878+fPzq1/9Kv/4j/+YqqqqJElVVdUeQVoqlTJixIh9fu3GxsY0NDR0ud+d1wIAoPdt\n3749s2bN6nK/rq4u9fX1PRupL730Uj7zmc9k06ZN+fu///uMHTu2Y2/UqFF7XAXdsmVLxo8fv8+v\nP2fOnEyfPn2ve/Pnz3clFQCg4IYNG5YlS5Z0uV9dXZ2kB9/ub29vT11dXZ555pncdtttecc73tFp\nf8KECVm1alXH1zt27Mj69etTX1+/z+eoqanZ477W1w0ePHi/5gYAoPdUVFSktrb2dx7XY5ce77jj\njqxYsSKXXnpphg8fni1btmTLli3ZunVrkmT27NlZtWpVFi9enKamppx//vkZN25cpk6d2lMjAADQ\nT7ypK6llZWUpKytLkvzgBz9Ie3t7PvvZz3Y6ZsqUKfn2t7+dMWPG5Nprr81ll12W66+/Pu95z3ve\n8P5SAAAGrjcVqU888UTHf//mN7/5O4+fNm1a7r333jdzSgAABgBPGgEAUDgiFQCAwhGpAAAUjkgF\nAKBwRCoAAIUjUgEAKByRCgBA4YhUAAAKR6QCAFA4IhUAgMIRqQAAFI5IBQCgcEQqAACFI1IBACgc\nkQoAQOGIVAAACkekAgBQOCIVAIDCEakAABSOSAUAoHBEKgAAhSNSAQAoHJEKAEDhiFQAAApHpAIA\nUDgiFQCAwhGpAAAUjkgFAKBwRCoAAIUjUgEAKByRCgBA4YhUAAAKR6QCAFA4IhUAgMIRqQAAFI5I\nBQCgcEQqAACFI1IBACgckQoAQOGIVAAACkekAgBQOPsdqaVSKTNnzswjjzzSsbZp06acffbZmTRp\nUk477bQ8+OCDnb7noYceysyZMzNx4sTMnTs3Gzdu3P/JAQDot/YrUkulUr74xS+mqamp0/qCBQtS\nU1OT5cuX5/TTT09dXV02b96cJHnuueeyYMGCzJ49O8uXL89BBx2UBQsWvPmfAACAfqfbkbphw4Z8\n9KMfzaZNmzqtP/zww9m4cWO++tWv5ogjjsi8efMyceLELFu2LEly++2355hjjsncuXNz5JFHZtGi\nRXnmmWc6XYkFAIBkPyJ1xYoVOeGEE9LY2Jj29vaO9bVr16a2tjZVVVUda5MnT87q1as79qdMmdKx\nN2TIkBx99NF57LHH3sz8AAD0Q4O6+w1nnXXWXtdbW1tTU1PTaW3kyJFpbm5OkrS0tOyxf8ghh3Ts\nAwDA67odqV3ZsWNHKisrO61VVlamVColSV555ZU33N8XLS0taW1t3evezp07U17uwwoAAIqsra0t\n69at63K/uro6NTU1PRepVVVV2bp1a6e1UqmUIUOGdOz/xyAtlUoZMWLEPp+jsbExDQ0NXe5357UA\nAOh927dvz6xZs7rcr6urS319fc9F6qhRo/Z42n/Lli2prq7u2P+PV0G3bNmS8ePH7/M55syZk+nT\np+91b/78+a6kAgAU3LBhw7JkyZIu919vxx6L1AkTJmTx4sUplUodb+uvXLkyxx13XMf+qlWrOo7f\nsWNH1q9fn/r6+n0+R01NzR73tb5u8ODBb2J6AAB6Q0VFRWpra3/ncT126XHq1Kk59NBDs3DhwjQ1\nNeXmm2/O448/njPOOCNJMnv27KxatSqLFy9OU1NTzj///IwbNy5Tp07tqREAAOgn3lSklpWV/faF\nystz/fXXp7W1NbNnz873v//9XHfddRk9enSSZMyYMbn22muzfPnynHnmmdm2bdsb3l8KAMDA9abe\n7n/iiSc6fT127NgsXbq0y+OnTZuWe++9982cEgCAAcCTRgAAFI5IBQCgcEQqAACFI1IBACgckQoA\nQOGIVAAACkekAgBQOCIVAIDCEakAABSOSAUAoHBEKgAAhSNSAQAoHJEKAEDhiFQAAApHpAIAUDgi\nFQCAwhGpAAAUjkgFAKBwRCoAAIUjUgEAKByRCgBA4YhUAAAKR6QCAFA4IhUAgMIRqQAAFI5IBQCg\ncEQqAACFI1IBACgckQoAQOGIVAAACkekAgBQOCIVAIDCEakAABSOSAUAoHBEKgAAhSNSAQAoHJEK\nAEDhiFQAAApHpAIAUDgiFQCAwhGpAAAUTo9G6ubNm/PZz342kydPzsknn5y///u/79jbtGlTzj77\n7EyaNCmnnXZaHnzwwZ48NQAA/UiPRurnPve5DBs2LN/73vfyl3/5l7n66qtz//33J0nOPffc1NTU\nZPny5Tn99NNTV1eXzZs39+TpAQDoJwb11Au9+OKLWbNmTS677LKMGzcu48aNy7Rp0/KTn/wkw4cP\nz6ZNm3LHHXekqqoq8+bNy8MPP5xly5alrq6up0YAAKCf6LErqUOGDMnQoUOzfPny7Nq1K08//XRW\nrVqV8ePHZ82aNamtrU1VVVXH8ZMnT87q1at76vQAAPQjPRaplZWVufDCC/M//+f/zIQJE3Lqqafm\npJNOyuzZs9Pa2pqamppOx48cOTLNzc09dXoAAPqRHnu7P0k2bNiQ6dOn59Of/nR+/vOf55JLLskJ\nJ5yQHTt2pLKystOxlZWVKZVK3Xr9lpaWtLa27nVv586dKS/3YQUAAEXW1taWdevWdblfXV2dmpqa\nnovU1+8x/dGPfpTKysocffTR2bx5c2644YaccMIJeeGFFzodXyqVMmTIkG6do7GxMQ0NDV3ujxgx\nYr9mBwCgd2zfvj2zZs3qcr+uri719fU9F6nr1q3LO97xjk5XTMePH5+bbropo0aNylNPPdXp+C1b\ntqS6urpb55gzZ06mT5++17358+e7kgoAUHDDhg3LkiVLutx/vQ97LFJramry7//+79m1a1cGDXrt\nZZ9++un8wR/8QSZMmJCbbroppVKpI2JXrlyZ4447rtvn+I/3tr5u8ODBb+4HAADg966ioiK1tbW/\n87geu/Q4ffr0DBo0KBdccEF++ctf5oEHHshNN92UT37yk5kyZUoOPfTQLFy4ME1NTbn55pvz+OOP\n54wzzuip0wMA0I/0WKQOHz48S5YsSWtra84888x87Wtfy4IFC3LmmWemvLw8N9xwQ1pbWzN79ux8\n//vfz3XXXZfRo0f31OkBAOhHevTp/iOPPDLf+ta39ro3duzYLF26tCdPBwBAP+VJIwAACkekAgBQ\nOCIVAIDCEakAABSOSAUAoHBEKgAAhSNSAQAoHJEKAEDhiFQAAApHpAIAUDgiFQCAwhGpAAAUjkgF\nAKBwRCoAAIUjUgEAKByRCgBA4YhUAAAKR6QCAFA4IhUAgMIRqQAAFI5IBQCgcEQqAACFI1IBACgc\nkQoAQOGIVAAACkekAgBQOCIVAIDCEakAABTOoL4eAAB6UqlUypo1a/p6DAaICRMmpLKysq/H6JdE\nKgD9ypo1a3LOXy3NASPH9fUo9HPbfv2rLL4kmTJlSl+P0i+JVAD6nQNGjsuBo9/V12MAb4J7UgEA\nKByRCgBA4YhUAAAKR6QCAFA4IhUAgMIRqQAAFI5IBQCgcEQqAACFI1IBACgckQoAQOH0aKSWSqVc\nfPHFmTp1at73vvflb//2bzv2Nm3alLPPPjuTJk3KaaedlgcffLAnTw0AQD/So5F66aWX5uGHH84t\nt9ySr3/967n99ttz++23J0nOPffc1NTUZPny5Tn99NNTV1eXzZs39+TpAQDoJwb11Att3bo13/3u\nd7NkyZK8+93vTpJ86lOfypo1azJu3Lhs2rQpd9xxR6qqqjJv3rw8/PDDWbZsWerq6npqBAAA+oke\ni9SVK1fmgAMOyHHHHdexds455yRJbrrpptTW1qaqqqpjb/LkyVm9enVPnR4AgH6kx97u37hxY8aM\nGZM777wzH/7wh3PKKafk+uuvT3t7e1pbW1NTU9Pp+JEjR6a5ubmnTg8AQD/SY1dSX3755fzyl7/M\n7bffniuuuCKtra258MILM3To0OzYsSOVlZWdjq+srEypVOqp0wMA0I/0WKRWVFRk+/bt+cY3vpHR\no0cnSZ555pn8wz/8Q973vvflhRde6HR8qVTKkCFDunWOlpaWtLa27nVv586dKS/3iVoAAEXW1taW\ndevWdblfXV2dmpqanovUmpqaVFVVdQRqkhx++OFpbm7OqFGj8tRTT3U6fsuWLamuru7WORobG9PQ\n0NDl/ogRI7o3NAAAvWr79u2ZNWtWl/t1dXWpr6/vuUidMGFCXn311fz7v/973v72tydJNmzYkDFj\nxmTChAm56aabUiqVOt72X7lyZaeHrPbFnDlzMn369L3uzZ8/35VUAICCGzZsWJYsWdLl/usXMXss\nUg8//PC8//3vz8KFC3PRRReltbU1ixcvzoIFCzJlypQceuihWbhwYc4999w88MADefzxx3PFFVd0\n6xw1NTV7PID1usGDB/fEjwEAwO9RRUVFamtrf+dxPXrp8etf/3re/va35+Mf/3jOP//8/Omf/mk+\n/vGPp7y8PDfccENaW1sze/bsfP/73891113X6dYAAAB4XY9dSU2S4cOH54orrtjrFdKxY8dm6dKl\nPXk6AAD6KTdxAgBQOCIVAIDCEakAABSOSAUAoHBEKgAAhSNSAQAoHJEKAEDhiFQAAApHpAIAUDgi\nFQCAwhGpAAAUjkgFAKBwRCoAAIUjUgEAKByRCgBA4YhUAAAKR6QCAFA4IhUAgMIRqQAAFI5IBQCg\ncEQqAACFI1IBACgckQoAQOGIVAAACkekAgBQOCIVAIDCEakAABSOSAUAoHBEKgAAhSNSAQAoHJEK\nAEDhiFQAAApHpAIAUDgiFQCAwhGpAAAUjkgFAKBwRCoAAIUjUgEAKByRCgBA4YhUAAAKR6QCAFA4\nIhUAgML5vUXqvHnzcv7553d8vWnTppx99tmZNGlSTjvttDz44IO/r1MDAPAW93uJ1Lvuuis/+tGP\nOq0tWLAgNTU1Wb58eU4//fTU1dVl8+bNv4/TAwDwFtfjkbp169ZcddVVOfbYYzvWHn744WzcuDFf\n/epXc8QRR2TevHmZOHFili1b1tOnBwCgHxjU0y/4ta99LR/5yEfS0tLSsbZ27drU1tamqqqqY23y\n5MlZvXp1T58eAIB+oEevpD788MNZuXJlFixY0Gm9tbU1NTU1ndZGjhyZ5ubmnjw9AAD9RI9dSS2V\nSvnrv/7rXHTRRamsrOy0t2PHjj3WKisrUyqVunWOlpaWtLa27nVv586dKS/3YQUAAEXW1taWdevW\ndblfXV2dmpqanovUa6+9Nu9+97tz4okn7rFXVVWVrVu3dlorlUoZMmRIt87R2NiYhoaGLvdHjBjR\nrdcDAKB3bd++PbNmzepyv66uLvX19T0XqXfffXd+/etfZ9KkSUleu7KZJP/6r/+az372s2lqaup0\n/JYtW1JdXd2tc8yZMyfTp0/f6978+fNdSQUAKLhhw4ZlyZIlXe6/3oc9Fqm33XZbdu3a1fH1VVdd\nlST58pe/nGeeeSY333xzSqVSx9v+K1euzHHHHdetc9TU1Oxxb+vrBg8evJ+TAwDQWyoqKlJbW/s7\nj+uxSD300EM7fT1s2LAkydixYzNmzJgceuihWbhwYc4999w88MADefzxx3PFFVf01OkBAOhHeuX9\n8fLy8lx//fVpbW3N7Nmz8/3vfz/XXXddRo8e3RunBwDgLabHPyf1dYsWLer09dixY7N06dLf1+kA\nAOhHPGkEAEDhiFQAAApHpAIAUDgiFQCAwhGpAAAUjkgFAKBwRCoAAIUjUgEAKByRCgBA4YhUAAAK\nR6QCAFA4IhUAgMIRqQAAFI5IBQCgcEQqAACFI1IBACgckQoAQOGIVAAACkekAgBQOCIVAIDCEakA\nABSOSAUAoHBEKgAAhSNSAQAoHJEKAEDhiFQAAApHpAIAUDgiFQCAwhGpAAAUjkgFAKBwRCoAAIUj\nUgEAKByRCgBA4YhUAAAKR6QCAFA4IhUAgMIRqQAAFI5IBQCgcEQqAACFI1IBACgckQoAQOH0aKQ2\nNzfnvPPOyx/+4R/m/e9/f6644oqUSqUkyaZNm3L22Wdn0qRJOe200/Lggw/25KkBAOhHejRSzzvv\nvLz66qv5h3/4h3zjG9/Iv/3bv+Waa65Jkpx77rmpqanJ8uXLc/rpp6euri6bN2/uydMDANBPDOqp\nF3r66aezdu3aPPjggzn44IOTvBatV155ZaZNm5ZNmzbljjvuSFVVVebNm5eHH344y5YtS11dXU+N\nAABAP9FjV1Krq6vzzW9+syNQX7dt27asWbMmtbW1qaqq6lifPHlyVq9e3VOnBwCgH+mxSD3ggAPy\n3ve+t+Pr9vb23HbbbTnhhBPS2tqampqaTsePHDkyzc3NPXV6AAD6kR57u/8/uvLKK/PEE09k2bJl\nufXWW1NZWdlpv7KysuOhqn3V0tKS1tbWve7t3Lkz5eU+rAAAoMja2tqybt26Lverq6tTU1Pz+4nU\nq666KkuXLs3VV1+dd77znamqqsrWrVs7HVMqlTJkyJBuvW5jY2MaGhq63B8xYsR+zQsAQO/Yvn17\nZs2a1eV+XV1d6uvrez5SL7nkkjQ2Nuaqq67KKaeckiQZNWpUmpqaOh23ZcuWVFdXd+u158yZk+nT\np+91b/78+a6kAgAU3LBhw7JkyZIu91/vwx6N1IaGhjQ2NuZv//Zv88EPfrBjfcKECVm8eHFKpVLH\n2/4rV67Mcccd163Xr6mp2ePe1tcNHjx4/wcHAKBXVFRUpLa29nce12OXHjds2JAbbrgh8+bNy6RJ\nk7Jly5aO/0ydOjWHHnpoFi5cmKamptx88815/PHHc8YZZ/TU6QEA6Ed67ErqD3/4w+zevTs33HBD\nbrjhhiSvPeFfVlaWJ554Itddd12+8pWvZPbs2Rk3blyuu+66jB49uqdODwBAP9JjkTpv3rzMmzev\ny/1x48Zl6dKlPXU6AAD6MU8aAQBQOCIVAIDCEakAABSOSAUAoHBEKgAAhSNSAQAoHJEKAEDhiFQA\nAApHpAIAUDgiFQCAwhGpAAAUjkgFAKBwRCoAAIUjUgEAKByRCgBA4YhUAAAKR6QCAFA4IhUAgMIR\nqQAAFI5IBQCgcEQqAACFI1IBACgckQoAQOGIVAAACkekAgBQOCIVAIDCEakAABSOSAUAoHBEKgAA\nhSNSAQAoHJEKAEDhiFQAAApHpAIAUDgiFQCAwhGpAAAUjkgFAKBwRCoAAIUjUgEAKByRCgBA4YhU\nAAAKR6QCAFA4vRqppVIpf/mXf5kpU6Zk2rRpufXWW3vz9AAAvEUM6s2Tfe1rX8v69euzdOnSbNq0\nKX/xF3+RMWPG5EMf+lBvjgEAQMH12pXUHTt2ZNmyZbngggty1FFH5ZRTTslnPvOZ3Hbbbb01AgAA\nbxG9FqmnortPAAAQAElEQVRPPvlk2traMnHixI61yZMnZ+3atb01AgAAbxG9Fqmtra058MADM2jQ\nb+8wGDlyZF599dX85je/6a0xAAB4C+jVt/srKys7rb3+dalU6q0xAAB4C+i1B6eqqqr2iNHXvx46\ndOg+vUZLS0taW1v3utfc3Jzdu3fn5JNPfnODDjCvvvpqtvzmpWwp79Vn6BiA2nfvyhe+cGeqqqr6\nehT6Ob/X6C1+r3Xfc889l4qKiqxbt67LY6qrq1NTU9N7kTpq1Ki88MIL2b17d8rLX7uAu2XLlgwZ\nMiQjRozYp9dobGxMQ0NDl/sVFRU9MutAUlVVlTGj/Y+rO9ra2rJ9+/YMGzbMvzkoIL/Xus/vNXrL\noEGD0t7enlmzZnV5TF1dXerr63svUsePH59BgwZl9erVec973pMkefTRR/Pud797n19jzpw5mT59\nepf7r5c3/D6tW7cus2bNypIlS1JbW9vX4wC8aX6v0Zve6J3x5LWeS3rx7f4hQ4bkIx/5SC666KJc\nfvnlaW5uzq233porrrhin1+jpqZGhAIAvIXta8/16g07559/fi6++OL82Z/9WQ444IB87nOfyymn\nnNKbIwAA8BbQq5E6ZMiQLFq0KIsWLerN0wIA8BbTax9BBQAA+0qkAgBQOCIVAIDCEanQTdXV1amr\nq+v4iAyAtzq/1yiisvb29va+HgIAAP5/rqQCAFA4IhUAgMIRqQAAFI5IBQCgcEQqAACFI1IBACgc\nkQoAQOGIVAAACkekAgBQOCIVAIDCGdTXAwAAvauhoWGv62VlZRk8eHBqamoybdq0jBw5spcng98q\na29vb+/rIaDoXnrppQwfPnyve/fff39OOeWUXp4IYP996Utfyt13353Ro0fn3e9+d9rb2/PEE0/k\n2WefzcSJE7Nt27Zs3rw53/zmNzNx4sS+HpcBytv9sA/+9E//NM8//3yntY0bN+acc87J5z//+T6a\nCmD/nXHGGbn//vtz7bXXpqGhIffdd1/+5E/+JO94xzvyL//yL/nMZz6TK664oq/HZAATqbAPxo4d\nm7POOivPPvtsSqVSrrnmmsyYMSOvvPJKli9f3tfjAXTLAw88kE996lOpqKjoWCsvL88nPvGJ3Hvv\nvUmSGTNm5Mknn+yrEcE9qbAvrrnmmlx22WX52Mc+lsrKyuzevTtf+9rX8uEPf7ivRwPotkMOOSSP\nPvpoDj/88E7rK1euzIEHHpgk2bJlS5e3OUFvEKmwD8rKynLBBRdk9OjRufrqq/PNb34zxx9/fF+P\nBbBf6uvr85WvfCUrV67MMccck/b29qxbty533XVXLrzwwvziF7/IX/zFX2TGjBl9PSoDmAenoAvT\np09PWVnZHuvNzc2pqKjIIYcc0rH2wx/+sDdHA3jTHn300fzjP/5jfv7zn6eioiLvfOc784lPfCIT\nJ07M2rVrs3r16nz84x/vdEsA9CaRCl343ve+t8/H/vEf//HvcRIAGHhEKuyjn/3sZ3n11Vdz7LHH\nJkluueWWnHjiiTnqqKP6eDKA7tm5c2fuvPPOPP7449m1a1f+YwosWrSojyaD3/J0P+yDu+++O2ee\neWZWrVrVsbZ27drMmTMn999/fx9OBtB9X/nKV3LZZZflN7/5zR6BCkXhSirsg//+3/97/sf/+B97\nvK3/3e9+N9/61rdy11139dFkAN03adKkNDQ05L3vfW9fjwJdciUV9sHmzZszadKkPdYnT56cjRs3\n9sFEAPvvgAMOyKhRo/p6DHhDIhX2wdFHH53bbrttj/Xbb7/dPanAW878+fNz2WWXZcOGDdm1a1df\njwN75e1+2Adr167Npz/96Rx44IEZP358ktcepHrhhRdy8803Z8KECX08IcC+mz59elpaWtLW1rbX\n/SeeeKKXJ4I9iVTYR88//3zuuuuu/OIXv8igQYPy9re/PaeffnoOOOCAvh4NoFtWrFjxhvtTp07t\npUmgayIVuuGXv/xlNmzYkN27d+fwww/PO9/5zr4eCQD6JX8WFfbBiy++mIULF+bf/u3fMmLEiLS1\ntWX79u2ZMmVKrrvuOldTgcI7+eSTs2zZshx00EFd/kW91/krehSBSIV9cOmll6a5uTl33XVXjjji\niCRJU1NTFi5cmEWLFuXyyy/v4wkB3lhdXV2GDRuWJKmvr+/jaeB383Y/7IPjjjsut956a4455phO\n62vXrs0555yTn/70p300GQD0T66kwj6oqqpKefmen9hWVlbW5dOxAEX14osv5pZbbunyz6J++9vf\n7qPJ4LdEKuyD6dOn5+KLL87Xv/71jBs3LslrD1Fdcsklef/739/H0wF0z5//+Z/n8ccfz8yZMzN8\n+PC+Hgf2ytv9sA9efPHFLFiwII8++mhGjBjRsTZt2rRceeWVOfDAA/t4QoB9d+yxx+a2227Lscce\n29ejQJdcSYXf4aWXXsrgwYOzdOnSPPnkk3n66adTVVWVww8/PMOHD8/ll1+eK6+8sq/HBNhno0aN\n2ustTFAkrqRCFzZv3pyFCxd2PBR10kkn5corr8x/+k//KW1tbVmyZEmuv/76DBo0yINTwFvKfffd\nl5tuuinnnXde3v72t2fw4MGd9g877LA+mgx+S6RCF84999w89dRTOe+88zJ48ODcfPPN+c//+T/n\nC1/4QubPn58nn3wyZ5xxRr7whS/koIMO6utxAfbZUUcd1enr1z8ztb29PWVlZf4sKoXg7X7owsqV\nK3P11VfnhBNOSJIcffTR+eM//uM8+eSTaW9vT2Nj4x4fSQXwVuDD+nkrcEMKdOHFF1/MkUce2fH1\nuHHjsnPnzowZMybLli0TqMBb1pgxYzJmzJi8/PLLWb9+fQ466KDs3r07hx12WMaMGdPX40ESV1Kh\nS+3t7amoqOi0VlFRkfr6+j3u3wJ4K9m6dWs+97nPZcWKFUmSf/3Xf81ll12WjRs35uabbxaqFIIr\nqdBNr/9ZQYC3qksvvTRDhw7NT37yk1RVVSVJLr/88owePTqXXnppH08Hr3ElFd7APffc0+mDrnfv\n3p0f/OAHGTlyZKfj/uiP/qi3RwPYbz/+8Y+zdOnSjs99TpKDDz44559/fj72sY/14WTwWyIVunDY\nYYfllltu6bQ2cuTIfOc73+m0VlZWJlKBt5xXX311j7Xnn38+gwZJA4rBv0TowgMPPNDXIwD8Xpx2\n2mm57LLL8tWvfjVlZWV5+eWX85Of/CQXXXRRTj311L4eD5L4nFQAGHBKpVK+8Y1v5Dvf+U527tyZ\nsrKyVFRU5IwzzsjChQszZMiQvh4RRCoADFSvvPJKNm7cmLa2towdOzbDhg3L888/n4MPPrivRwNP\n9wPAQDN+/Pg8//zzGTJkSN71rnflqKOOyrBhw/LMM8/k5JNP7uvxIIl7UgFgQLjzzjvz3e9+N8lr\nnwO9YMGCPT7zuaWlJdXV1X0xHuxBpALAAPDBD34wmzZtSpKsWLEiEydO3ONzn9/2trflgx/8YF+M\nB3twTyoADDDf+973MmPGjFRWVvb1KNAl96QCwAAzc+bMLF++PM8++2yS5JprrsmMGTPy5S9/OS+8\n8EIfTwevEakAMMBcccUVuf766/Piiy/m/vvvz+LFi/ORj3wkzz33XC655JK+Hg+SeLsfAAacE088\nMddff30mTpyYL33pS9m+fXtuvPHGPPXUU/nYxz6WlStX9vWI4EoqAAw0O3bsyMiRI7Nr16786Ec/\nygc+8IEkye7du/1ZVArDv0QAGGDe85735Kqrrsrw4cOzY8eOnHLKKXnyySdzySWX5Pjjj+/r8SCJ\nK6kAMOBceuml2blzZ9atW5dFixZl5MiRueeeezJy5MhcdNFFfT0eJHFPKgAABeTtfgAYABoaGvLp\nT386Q4cOTUNDwxseW1dX10tTQddEKgAMAD/96U/zyU9+MkOHDs1Pf/rTNzxWpFIE3u4HAKBwPDgF\nACRJVqxYkf/6X/9rX48BSUQqAPD/vPrqq2lubu7rMSCJSAUAoIBEKgAAhSNSAQAoHB9BBQADwFFH\nHZWysrI3PKa9vf13HgO9RaQCwADw7W9/u69HgG7xOakAABSOe1IBACgckQoAQOGIVAAACkekAsAA\n83d/93fZsGFDX48Bb0ikAsAAs379+vzRH/1RTj/99Nx0003ZuHFjX48Ee/B0PwAMQC+99FLuu+++\n3HvvvXnooYdy1FFHZcaMGfnwhz+cUaNG9fV4IFIBYKDbtm1bvvWtb+XWW2/Nzp07M3ny5MyZMyen\nnXZaX4/GACZSAWCAeuyxx3LvvffmBz/4QbZu3ZqTTz45p556alpbW3PjjTfmuOOOy5VXXtnXYzJA\n+YtTADDAXHbZZbnvvvvy61//OieddFK+/OUv5+STT05VVVXHMcOGDcsFF1zQh1My0LmSCgADzKc+\n9anMmDEjH/rQh3LAAQfs9Zhf/epX2bRpU0488cReng5eI1IBYIDavXt3ysvL09LSkpUrV+a//Jf/\nkiOOOKKvx4IkPoIKAAaclStXZtq0aVmxYkVaWloya9asXHjhhTn99NNzzz339PV4kESkAsCAc/nl\nl+fUU0/NhAkTcvvtt6eqqioPPvhgLrnkkvzd3/1dX48HSUQqAAw4Tz31VP7sz/4sQ4cOzQMPPJAP\nfehDqayszNSpU/Pss8/29XiQRKQCwIBzyCGHpKmpKU1NTVm/fn0+8IEPJEkeeuihHHrooX08HbzG\nR1ABwAAzd+7cLFiwIOXl5TnmmGMyderU3HjjjWloaMiiRYv6ejxI4ul+ABiQ1q9fn2effTbve9/7\nMmTIkKxevTpDhgzJUUcd1dejQRKRCgD8P6VSKU888UQmTJjQ16OAt/sBYKBZtWpVLr744jQ1NWX3\n7t2d9ioqKvJ//s//6aPJ4Lc8OAUAA8yll16aMWPG5MYbb8zQoUNz7bXX5oILLsiBBx6YK6+8sq/H\ngySupALAgPPUU0/lqquuypFHHpna2toMHjw4H//4xzNy5MgsXrw4p556al+PCK6kAsBAM3To0FRU\nVCRJjjjiiPzsZz9Lkhx77LH5xS9+0ZejQQeRCgADzPHHH5+/+Zu/SXNzcyZNmpS77747L7zwQh54\n4IGMGDGir8eDJCIVAAacr3zlK9m6dWt+8IMfZMaMGRk+fHiOP/74LFq0KAsWLOjr8SCJj6ACgAGv\nvb09TU1NGTFiREaNGtXX40ASV1IBYEB45JFHsmvXrr3ulZWV5V3veldGjBiRG2+8sZcng70TqQAw\nAHzyk5/M1q1bO63NnDkzzz33XMfX27dvzzXXXNPbo8FeiVQAGAD2dnffpk2bury6Cn1NpAIAUDgi\nFQCAwhGpAAAUjj+LCgADxD333JPhw4d3fL179+7cd999Ofjgg5Mk27Zt66vRYA8+JxUABoDp06fv\n87EPPPDA73ES2DciFQCAwnFPKgAAhSNSAQAoHJEKAEDhiFQAAApHpAIAUDgiFQCAwhGpAAAUjkgF\nAKBw/i+X9iFywWhZ5QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x102e78450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aggregate data to song level to see how many songs are of each genre\n",
    "my_itunes_data[['song_id', 'genre']].drop_duplicates()['genre'].value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got about twice the number of Rock songs than Easy Listening, but should be fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 183 songs in the training set and 25 songs in the test set\n"
     ]
    }
   ],
   "source": [
    "# Get the list of unique song_id's\n",
    "unique_song_ids = my_itunes_data['song_id'].unique()\n",
    "\n",
    "# Get ~10% of the test data\n",
    "test_song_ids = random.sample(unique_song_ids, 25)\n",
    "\n",
    "# All other songs become the training set\n",
    "train_song_ids = [x for x in unique_song_ids if x not in test_song_ids]\n",
    "\n",
    "print 'There are {} songs in the training set and {} songs in the test set'.format(len(train_song_ids), len(test_song_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1187d94d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqEAAAIxCAYAAAB9xGEdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAQBIToQCAJCcCAUAIDkRCgBAcv8P23pNhXa6buIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1034cc510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the distribution of genres in the test set to ensure the sample is not completely lop-sided\n",
    "my_itunes_data[my_itunes_data['song_id'].isin(test_song_ids)][['song_id', 'genre']].drop_duplicates()['genre'].value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking good. Let's train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 118218 training samples\n",
      "There are 16150 test samples\n"
     ]
    }
   ],
   "source": [
    "# Build training set\n",
    "x_train = my_itunes_data[my_itunes_data['song_id'].isin(train_song_ids)].filter(regex = 'mfcc.*').values\n",
    "y_train = my_itunes_data[my_itunes_data['song_id'].isin(train_song_ids)][['genre']].values.T[0]\n",
    "print 'There are {} training samples'.format(len(x_train))\n",
    "\n",
    "# Build test set\n",
    "x_test = my_itunes_data[my_itunes_data['song_id'].isin(test_song_ids)].filter(regex = 'mfcc.*').values\n",
    "y_test = my_itunes_data[my_itunes_data['song_id'].isin(test_song_ids)][['genre']].values.T[0]\n",
    "print 'There are {} test samples'.format(len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import xgboost\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y (train) set has the following labels [0 1] and has 118218 elements\n",
      "Y (test) set has the following labels [0 1] and has 16150 elements\n"
     ]
    }
   ],
   "source": [
    "# Encode our labels to integers (e.g. \"Dance\" becomes a number like 1 or 2)\n",
    "lb = LabelEncoder()\n",
    "y_train_encoded = lb.fit_transform(y_train)\n",
    "y_test_encoded = lb.transform(y_test)\n",
    "print 'Y (train) set has the following labels {} and has {} elements'.format(np.unique(y_train_encoded), len(y_train_encoded))\n",
    "print 'Y (test) set has the following labels {} and has {} elements'.format(np.unique(y_test_encoded), len(y_test_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit our train and test data to a xgb sparse matrix\n",
    "xgb_train = xgb.DMatrix(x_train, label = y_train_encoded)\n",
    "xgb_test = xgb.DMatrix(x_test, label = y_test_encoded)\n",
    "xgb_test_no_label = xgb.DMatrix(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set xgboost parameters\n",
    "param = {\n",
    "    'max_depth': 1,\n",
    "    'nthread': 2,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'silent': 1\n",
    "}\n",
    "\n",
    "num_rounds = 10000\n",
    "\n",
    "eval_list  = [(xgb_train, 'train'), (xgb_test, 'eval')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This great. We can train our model MUCH faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train model\n",
    "bst = xgb.train(param, xgb_train, num_rounds, eval_list, early_stopping_rounds = 250, verbose_eval = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model was on iteration 176 with a score of 0.549914\n"
     ]
    }
   ],
   "source": [
    "# Define a function to output best model info\n",
    "def best_model_info(bst):\n",
    "    print 'The best model was on iteration {} with a score of {}'.format(bst.best_iteration, bst.best_score)\n",
    "    \n",
    "# View best model info from last train\n",
    "best_model_info(bst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we only have 2 classes for this example, we can actually use xgboost to evaluate the AUC rather than straight classification error. AUC will give us a better sense of how well the model is able to separate out sensitivity and specificity of the classes. Because each iteration of xgboost is so fast here, I can also just set the maximum number of rounds to something crazy like 10,000 and set the early_stopping_rounds parameter as well. As we saw in the R implementation, early_stopping_rounds simply allows us to run the model into oblivion and xgboost itself will automatically stop when the evaluation metric doesn't get better for, as we've set here, 250 iterations. Here, I turned 'silent': 1 in the model params verbose_eval = False in the train command to surpess the information because the bst parameter should give us all the information we need without needing to see every iteration's information.\n",
    "\n",
    "Since our model is training so fast, we can tweak a few parameters... one that I've been ignoring is the eta parameter which controls the learning rate. The xgboost default is 0.3 which isn't that big, but we can decrease it even more because time we have time to spare with the model training so quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tweak eta parameter\n",
    "param_eta_01 = param\n",
    "param_eta_01['eta'] = 0.1\n",
    "\n",
    "# Train model\n",
    "bst_eta_01 = xgb.train(param, xgb_train, num_rounds, eval_list, early_stopping_rounds = 250, verbose_eval = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model was on iteration 1558 with a score of 0.54947\n"
     ]
    }
   ],
   "source": [
    "# View best model info from last train\n",
    "best_model_info(bst_eta_01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're not doing much better here. I doubt things would change if we slowed it down even more but..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tweak eta parameter\n",
    "param_eta_005 = param\n",
    "param_eta_005['eta'] = 0.05\n",
    "\n",
    "# Train model\n",
    "bst_eta_005 = xgb.train(param, xgb_train, num_rounds, eval_list, early_stopping_rounds = 250, verbose_eval = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model was on iteration 768 with a score of 0.548409\n"
     ]
    }
   ],
   "source": [
    "# View best model info from last train\n",
    "best_model_info(bst_eta_005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, it actually took less iterations to train at a learning rate of 0.05 than at 0.1. I can maybe attribute that to the luck of the draw in that the 0.1 step size may have just made a few splits that prolonged the training process, where 0.05 was able to get to the point a bit faster. Regardless, we se a similar AUC, and it's not good.\n",
    "\n",
    "![](https://media.giphy.com/media/yisc7FaqoEfjG/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I just want to take a bit of a deeper dive to see which songs were classified what just to see if I can find out a bit more information that way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict test\n",
    "y_test_pred = bst_eta_005.predict(xgb_test_no_label, ntree_limit = bst_eta_005.best_ntree_limit)\n",
    "y_test_pred = [int(x) for x in y_test_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x117482390>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqEAAAIxCAYAAAB9xGEdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niVAAANKJUAAA0olQAADS/X86LypN8SuAIAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1150eb410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a new dataframe with just the song ids\n",
    "x_test_song_id_labels = my_itunes_data[my_itunes_data['song_id'].isin(test_song_ids)][['song_id']].reset_index(drop = True)\n",
    "\n",
    "# Append the predicted values to the song ids\n",
    "x_test_song_id_labels['y_test_pred'] = pd.Series(lb.inverse_transform(y_test_pred))\n",
    "\n",
    "# Group by and find the most commonly classified genre of each frame per song\n",
    "song_classification = x_test_song_id_labels.groupby(['song_id'])['y_test_pred'].agg(lambda x: x.value_counts().idxmax()).reset_index()\n",
    "\n",
    "# Plot histogram of predicted song genres\n",
    "song_classification['y_test_pred'].value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh wow, that's quite unexpected... it thinks everything is easy listening. Okay then. This doesn't quite solve any of the problems I had haha... probably just creates more to be honest. There is still a chance that my music classification is wrong, and there is still a chance that I'm extracting MFCCs wrong or that MFCCs are a wrong way to approach the problem in general. There is one _**last**_ thing I can try to tweak in the xgboost model, and that's the depth of the trees. I don't expect much of a difference, but let's give it a shot. Since we're playing around with multiple parameters here, I'm actually going to try the GridSearchCV function from sklearn.\n",
    "\n",
    "The GridSearchCV essentially allows us to\n",
    "1. Perform cross validation (which we had not been doing before, we were only using a single train test split)\n",
    "2. Loop through multiple parameters efficiently\n",
    "\n",
    "I have to caveat this right now by saying that _**MY METHOD OF CV RIGHT NOW MAY BE INACCURATE**_. Cross validation helps decrease the out-of-sample error by splitting our data up into multiple folds and training and testing multiple times. For example, for 5-fold cross validation, each iteration would look something like this:\n",
    "\n",
    "![](http://tomaszkacmajor.pl/wp-content/uploads/2016/05/cross-validation.png)\n",
    "\n",
    "Notice that each set is split up into 1 parts, and in each iteration, 4 of them are used as training and 1 of them is used as the test. The reason I wasn't using CV before, and only train test split, was because each of my training samples are _**frames of songs**_, not the _**actual songs themselves**_. Because they are frames, I may be training on parts of one song, and testing on other parts. Although, in theory, each sample is individual from each other, the logic in the context we're working in (music and songs) says we should be training and testing on _**songs**_ themselves.\n",
    "\n",
    "For me to run cross validation, let alone cross validation over a grid of parameters like GridSearchCV does, I'd have to write custom code (like I did with the train test split method) to not just randomly take 20% of my sample, but 20% of my sample _**in terms of songs**_, which ends up being 20% of the overall samples in general because I took the same amount of samples per song. I should never be training on 50% of one song and testing on 50% of another song.\n",
    "\n",
    "But with that entire rant, I'm going to go ahead and actually do exactly that because my objective here is just to scratch the surface on if parameters make a big difference, not do a deep dive. This should give me enough of an idea because I think I should still see a bump in accuracy.\n",
    "\n",
    "To learn how GridSearchCV works with xgboost, I'm referring to [this kaggle page](https://www.kaggle.com/phunter/xgboost-with-gridsearchcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "xgb_model_test = xgb.XGBClassifier()\n",
    "\n",
    "# Set parameters (for GridSearchCV, every value must be in a list, even if there is only 1 value we want to test)\n",
    "param_grid_search_test = {\n",
    "#     'max_depth': [1, 5, 10],\n",
    "#     'learning_rate': [0.05, 0.1, 0.5, 1, 2],\n",
    "    'max_depth': [1],\n",
    "    'objective': ['binary:logistic'],\n",
    "    'silent': [1],\n",
    "#     'n_estimators': 1000\n",
    "    'n_estimators': [200]\n",
    "}\n",
    "\n",
    "# Set up grid search\n",
    "clf_test = GridSearchCV(\n",
    "    xgb_model_test, \n",
    "    param_grid_search_test, \n",
    "    n_jobs = -1, \n",
    "    cv = 5, \n",
    "    scoring = 'roc_auc',\n",
    "    verbose = 1, \n",
    "    refit = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Suppress warnings because I'm getting a deprecation warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit model\n",
    "clf_test.fit(x_train, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.540156962394\n",
      "{'n_estimators': 200, 'objective': 'binary:logistic', 'max_depth': 1, 'silent': 1}\n"
     ]
    }
   ],
   "source": [
    "print clf_test.best_score_\n",
    "print clf_test.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I just tried a test run above, and I've gotten the model to train! Hurrah! You'll see that my parameters list contains some commented out values of parameters that I actually want to train, but I just wanted to do a test run first because I could be waiting a while if something went wrong. Training 5 models (1 model with 5 CV) took about 45 seconds here, so not bad!\n",
    "\n",
    "I'm going to extend this training process, first of all, by using 1000 iterations instead of 200. I'm then going to add 12x more models (3 max_depth values and 4 eta values), in certain cases using larger tree depths, and using slower learning rates as well. Let's try it anyways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "\n",
    "# Set parameters (for GridSearchCV, every value must be in a list, even if there is only 1 value we want to test)\n",
    "param_grid_search = {\n",
    "    'max_depth': [1, 5, 10],\n",
    "    'learning_rate': [0.05, 0.1, 0.5, 1, 2],\n",
    "    'objective': ['binary:logistic'],\n",
    "    'silent': [1],\n",
    "    'n_estimators': [1000]\n",
    "}\n",
    "\n",
    "# Set up grid search\n",
    "clf = GridSearchCV(\n",
    "    xgb_model, \n",
    "    param_grid_search, \n",
    "    n_jobs = -1, \n",
    "    cv = 5, \n",
    "    scoring = 'roc_auc',\n",
    "    verbose = 2, \n",
    "    refit = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=1, silent=1 \n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=1, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=1, silent=1 -  48.5s\n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=1, silent=1 -  48.9s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=1, silent=1 \n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=1, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=1, silent=1 -  46.5s\n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=1, silent=1 -  46.5s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=1, silent=1 \n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=5, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=1, silent=1 -  46.0s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=5, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=5, silent=1 - 3.5min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=5, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=5, silent=1 - 3.5min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=5, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=5, silent=1 - 3.5min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=5, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=5, silent=1 - 3.5min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=5, silent=1 -123.2min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=10, silent=1 -425.5min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=10, silent=1 -305.8min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=10, silent=1 - 8.1min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=10, silent=1 - 8.2min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=1, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=1, silent=1 -  45.7s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=1, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=1, silent=1 -  45.9s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=1, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=1, silent=1 -  46.0s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=1, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=1, silent=1 -  46.5s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=1, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=1, silent=1 -  45.7s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=5, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=10, silent=1 - 7.4min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=5, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=5, silent=1 - 3.5min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=5, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=5, silent=1 - 3.5min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=5, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=5, silent=1 - 3.5min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=5, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=5, silent=1 - 3.5min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=5, silent=1 - 3.5min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=10, silent=1 - 7.3min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=10, silent=1 - 7.3min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=10, silent=1 - 7.3min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=10, silent=1 - 7.3min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=1, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=1, silent=1 -  45.6s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=1, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=1, silent=1 -  45.8s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=1, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=1, silent=1 -  49.4s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=1, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=1, silent=1 -  45.6s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=1, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=1, silent=1 -  45.9s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=5, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=10, silent=1 - 7.4min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=5, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=5, silent=1 - 4.8min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=5, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=5, silent=1 - 5.2min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=5, silent=1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed: 484.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=5, silent=1 - 5.5min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=5, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=5, silent=1 - 5.1min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=5, silent=1 - 3.5min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=10, silent=1 - 7.3min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=10, silent=1 - 7.3min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=10, silent=1 - 7.3min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=10, silent=1 - 7.3min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=1, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=1, silent=1 -  45.6s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=1, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=1, silent=1 -  45.5s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=1, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=1, silent=1 -  45.6s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=1, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=1, silent=1 -  46.1s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=1, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=1, silent=1 -  45.5s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=5, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=10, silent=1 - 7.3min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=5, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=5, silent=1 - 3.5min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=5, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=5, silent=1 - 3.5min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=5, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=5, silent=1 - 3.8min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=5, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=5, silent=1 - 3.8min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=5, silent=1 - 3.8min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=10, silent=1 - 7.3min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=10, silent=1 - 7.6min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=10, silent=1 - 8.4min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=10, silent=1 - 8.9min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=1, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=1, silent=1 -  29.7s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=1, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=1, silent=1 -  28.1s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=1, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=1, silent=1 -  28.7s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=1, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=1, silent=1 -  25.5s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=1, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=1, silent=1 -  27.8s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=5, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=5, silent=1 -  35.9s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=5, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=5, silent=1 -  31.7s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=5, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=5, silent=1 -  35.4s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=5, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=10, silent=1 - 8.3min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=5, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=5, silent=1 -  34.9s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=5, silent=1 -  38.2s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=10, silent=1 - 5.3min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=10, silent=1 - 5.4min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=10, silent=1 - 4.1min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=10, silent=1 - 4.1min\n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=10, silent=1 - 3.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  75 out of  75 | elapsed: 556.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'objective': ['binary:logistic'], 'n_estimators': [1000], 'learning_rate': [0.05, 0.1, 0.5, 1, 2], 'max_depth': [1, 5, 10], 'silent': [1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "clf.fit(x_train, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.687249669247\n",
      "{'n_estimators': 1000, 'objective': 'binary:logistic', 'learning_rate': 0.05, 'max_depth': 5, 'silent': 1}\n"
     ]
    }
   ],
   "source": [
    "print clf.best_score_\n",
    "print clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, that actually made quite a difference. We see with a slower learning rate and more depth in our trees, we've gained ~15% more area under our ROC curve! That's awesome. At the risk of sounding like an addict, I must go deeper here.\n",
    "\n",
    "<img src=\"http://i0.kym-cdn.com/photos/images/facebook/000/531/557/a88.jpg\" style=\"width: 400px;\"/>\n",
    "\n",
    "Let me re-run the model with even more fine-tuned learning rates and max\\_depths. I also bumped the number of rounds up to 10,000 becauwe we are using _**much smaller step sizes**_ (learning rates / etas). I've also just found out that you can implement xgboost early stopping in conjunction with GridSearchCV as well... life just keeps getting better... goodness gracious. One caveat of this is that, when we implmented early stopping before, we had a consistent training set and a consistent test set. This made sense because, while our training error keeps decreasing, our test error is what our early stopping measured on. If the test error doesn't improve in however many specified iterations, we stop the process altogether because it looks like we've found a minimum in test error. When we're doing cross validation, _**our training set is always changing**_. There exists a chance that our randomly defined training set actually overlaps with our test set specified for early stopping, and that the test error will keep decreasing with the CV train error. Our training set created by CV, however, takes up 80% of our data because we're using 5-fold CV, and our early stopping test set takes up 10% of our data because I've defined that number at the top of the script, so already our two data sets _**overlap directly, even by pure chance**_, but I won't pretend like there doesn't exist any possibility of correlation here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "xgb_model_detailed = xgb.XGBClassifier()\n",
    "\n",
    "# Set parameters (for GridSearchCV, every value must be in a list, even if there is only 1 value we want to test)\n",
    "param_detailed = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.03, 0.05],\n",
    "    'objective': ['binary:logistic'],\n",
    "    'silent': [1],\n",
    "    'n_estimators': [10000]\n",
    "}\n",
    "\n",
    "fit_params_detailed = {\n",
    "    'early_stopping_rounds': 200,\n",
    "    'eval_metric': 'auc',\n",
    "    'eval_set': [[x_test, y_test_encoded]],\n",
    "    'verbose': 1000\n",
    "}\n",
    "\n",
    "# Set up grid search\n",
    "clf_detailed = GridSearchCV(\n",
    "    xgb_model_detailed,\n",
    "    param_detailed,\n",
    "    fit_params = fit_params_detailed,\n",
    "    n_jobs = -1,\n",
    "    cv = 5, \n",
    "    scoring = 'roc_auc',\n",
    "    verbose = 2,\n",
    "    refit = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] n_estimators=10000, objective=binary:logistic, learning_rate=0.01, max_depth=3, silent=1 \n",
      "[CV] n_estimators=10000, objective=binary:logistic, learning_rate=0.01, max_depth=3, silent=1 \n",
      "[0]\tvalidation_0-auc:0.513271\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[0]\tvalidation_0-auc:0.512725\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[1000]\tvalidation_0-auc:0.687086\n",
      "[1000]\tvalidation_0-auc:0.662171\n",
      "[2000]\tvalidation_0-auc:0.699414\n",
      "[2000]\tvalidation_0-auc:0.675056\n",
      "[3000]\tvalidation_0-auc:0.705612\n",
      "[3000]\tvalidation_0-auc:0.684401\n",
      "[4000]\tvalidation_0-auc:0.715883\n",
      "[4000]\tvalidation_0-auc:0.693425\n",
      "Stopping. Best iteration:\n",
      "[4018]\tvalidation_0-auc:0.716013\n",
      "\n",
      "[CV]  n_estimators=10000, objective=binary:logistic, learning_rate=0.01, max_depth=3, silent=1 - 9.5min\n",
      "[CV] n_estimators=10000, objective=binary:logistic, learning_rate=0.01, max_depth=3, silent=1 \n",
      "[0]\tvalidation_0-auc:0.593536\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[41]\tvalidation_0-auc:0.640459\n",
      "\n",
      "[CV]  n_estimators=10000, objective=binary:logistic, learning_rate=0.01, max_depth=3, silent=1 -  30.7s\n",
      "[CV] n_estimators=10000, objective=binary:logistic, learning_rate=0.01, max_depth=3, silent=1 \n",
      "[0]\tvalidation_0-auc:0.529008\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[5000]\tvalidation_0-auc:0.697094\n",
      "[1000]\tvalidation_0-auc:0.67888\n",
      "[6000]\tvalidation_0-auc:0.702122\n",
      "[2000]\tvalidation_0-auc:0.704916\n",
      "[7000]\tvalidation_0-auc:0.705753\n",
      "Stopping. Best iteration:\n",
      "[7339]\tvalidation_0-auc:0.70633\n",
      "\n",
      "[3000]\tvalidation_0-auc:0.711303\n",
      "[CV]  n_estimators=10000, objective=binary:logistic, learning_rate=0.01, max_depth=3, silent=1 -16.9min\n",
      "[CV] n_estimators=10000, objective=binary:logistic, learning_rate=0.01, max_depth=3, silent=1 \n",
      "[0]\tvalidation_0-auc:0.547004\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[4000]\tvalidation_0-auc:0.717105\n",
      "[1000]\tvalidation_0-auc:0.672362\n",
      "[5000]\tvalidation_0-auc:0.719302\n",
      "[2000]\tvalidation_0-auc:0.701345\n",
      "Stopping. Best iteration:\n",
      "[5716]\tvalidation_0-auc:0.719824\n",
      "\n",
      "[CV]  n_estimators=10000, objective=binary:logistic, learning_rate=0.01, max_depth=3, silent=1 -13.0min\n",
      "[CV] n_estimators=10000, objective=binary:logistic, learning_rate=0.01, max_depth=5, silent=1 \n",
      "[0]\tvalidation_0-auc:0.608486\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[3000]\tvalidation_0-auc:0.714536\n",
      "[4000]\tvalidation_0-auc:0.724379\n",
      "[1000]\tvalidation_0-auc:0.72224\n",
      "[5000]\tvalidation_0-auc:0.728133\n",
      "[6000]\tvalidation_0-auc:0.729875\n",
      "[2000]\tvalidation_0-auc:0.730951\n",
      "Stopping. Best iteration:\n",
      "[6384]\tvalidation_0-auc:0.731164\n",
      "\n",
      "[CV]  n_estimators=10000, objective=binary:logistic, learning_rate=0.01, max_depth=3, silent=1 -14.5min\n",
      "[CV] n_estimators=10000, objective=binary:logistic, learning_rate=0.01, max_depth=5, silent=1 \n",
      "[0]\tvalidation_0-auc:0.577959\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[3000]\tvalidation_0-auc:0.734651\n",
      "Stopping. Best iteration:\n",
      "[3203]\tvalidation_0-auc:0.735014\n",
      "\n",
      "[1000]\tvalidation_0-auc:0.704814\n",
      "[CV]  n_estimators=10000, objective=binary:logistic, learning_rate=0.01, max_depth=5, silent=1 -12.2min\n",
      "[CV] n_estimators=10000, objective=binary:logistic, learning_rate=0.01, max_depth=5, silent=1 \n",
      "[0]\tvalidation_0-auc:0.638069\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[2000]\tvalidation_0-auc:0.710087\n",
      "[1000]\tvalidation_0-auc:0.735768\n",
      "Stopping. Best iteration:\n",
      "[2355]\tvalidation_0-auc:0.710818\n",
      "\n",
      "[CV]  n_estimators=10000, objective=binary:logistic, learning_rate=0.01, max_depth=5, silent=1 - 9.2min\n",
      "[CV] n_estimators=10000, objective=binary:logistic, learning_rate=0.01, max_depth=5, silent=1 \n",
      "[0]\tvalidation_0-auc:0.61347\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[2000]\tvalidation_0-auc:0.743294\n",
      "[1000]\tvalidation_0-auc:0.725555\n",
      "[3000]\tvalidation_0-auc:0.748411\n",
      "Stopping. Best iteration:\n",
      "[1516]\tvalidation_0-auc:0.731235\n",
      "\n",
      "[CV]  n_estimators=10000, objective=binary:logistic, learning_rate=0.01, max_depth=5, silent=1 - 6.1min\n",
      "[CV] n_estimators=10000, objective=binary:logistic, learning_rate=0.01, max_depth=5, silent=1 \n",
      "[0]\tvalidation_0-auc:0.634673\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[3482]\tvalidation_0-auc:0.749508\n",
      "\n",
      "[CV]  n_estimators=10000, objective=binary:logistic, learning_rate=0.01, max_depth=5, silent=1 -13.3min\n",
      "[CV] n_estimators=10000, objective=binary:logistic, learning_rate=0.01, max_depth=7, silent=1 \n",
      "[0]\tvalidation_0-auc:0.656364\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[1000]\tvalidation_0-auc:0.726576\n",
      "[1000]\tvalidation_0-auc:0.739362\n",
      "[2000]\tvalidation_0-auc:0.736592\n",
      "[3000]\tvalidation_0-auc:0.739477\n",
      "[2000]\tvalidation_0-auc:0.743048\n",
      "Stopping. Best iteration:\n",
      "[2023]\tvalidation_0-auc:0.743085\n",
      "\n",
      "[CV]  n_estimators=10000, objective=binary:logistic, learning_rate=0.01, max_depth=7, silent=1 -11.3min\n",
      "[CV] n_estimators=10000, objective=binary:logistic, learning_rate=0.01, max_depth=7, silent=1 \n",
      "[0]\tvalidation_0-auc:0.628367\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[3788]\tvalidation_0-auc:0.741162\n",
      "\n",
      "[CV]  n_estimators=10000, objective=binary:logistic, learning_rate=0.01, max_depth=5, silent=1 -14.5min\n",
      "[CV] n_estimators=10000, objective=binary:logistic, learning_rate=0.01, max_depth=7, silent=1 \n",
      "[0]\tvalidation_0-auc:0.683078\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[1000]\tvalidation_0-auc:0.717887\n",
      "[1000]\tvalidation_0-auc:0.750089\n",
      "Stopping. Best iteration:\n",
      "[1239]\tvalidation_0-auc:0.718534\n",
      "\n",
      "[CV]  n_estimators=10000, objective=binary:logistic, learning_rate=0.01, max_depth=7, silent=1 - 7.3min\n",
      "[CV] n_estimators=10000, objective=binary:logistic, learning_rate=0.01, max_depth=7, silent=1 \n",
      "[0]\tvalidation_0-auc:0.643099\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1403]\tvalidation_0-auc:0.751613\n",
      "\n",
      "[CV]  n_estimators=10000, objective=binary:logistic, learning_rate=0.01, max_depth=7, silent=1 - 8.2min\n",
      "[CV] n_estimators=10000, objective=binary:logistic, learning_rate=0.01, max_depth=7, silent=1 \n",
      "[0]\tvalidation_0-auc:0.631997\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[1000]\tvalidation_0-auc:0.736829\n",
      "[1000]\tvalidation_0-auc:0.738855\n",
      "Stopping. Best iteration:\n",
      "[1231]\tvalidation_0-auc:0.73776\n",
      "\n",
      "[CV]  n_estimators=10000, objective=binary:logistic, learning_rate=0.01, max_depth=7, silent=1 - 7.4min\n",
      "[CV] n_estimators=10000, objective=binary:logistic, learning_rate=0.03, max_depth=3, silent=1 \n",
      "[0]\tvalidation_0-auc:0.513271\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1259]\tvalidation_0-auc:0.740317\n",
      "\n",
      "[1000]\tvalidation_0-auc:0.713865\n",
      "[CV]  n_estimators=10000, objective=binary:logistic, learning_rate=0.01, max_depth=7, silent=1 - 7.5min\n",
      "[CV] n_estimators=10000, objective=binary:logistic, learning_rate=0.03, max_depth=3, silent=1 \n",
      "[0]\tvalidation_0-auc:0.512725\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[2000]\tvalidation_0-auc:0.724701\n",
      "[1000]\tvalidation_0-auc:0.690355\n",
      "Stopping. Best iteration:\n",
      "[2695]\tvalidation_0-auc:0.729172\n",
      "\n",
      "[CV]  n_estimators=10000, objective=binary:logistic, learning_rate=0.03, max_depth=3, silent=1 - 6.2min\n",
      "[CV] n_estimators=10000, objective=binary:logistic, learning_rate=0.03, max_depth=3, silent=1 \n",
      "[0]\tvalidation_0-auc:0.593536\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[2000]\tvalidation_0-auc:0.705169\n",
      "Stopping. Best iteration:\n",
      "[2582]\tvalidation_0-auc:0.708276\n",
      "\n",
      "[CV]  n_estimators=10000, objective=binary:logistic, learning_rate=0.03, max_depth=3, silent=1 - 5.9min\n",
      "[CV] n_estimators=10000, objective=binary:logistic, learning_rate=0.03, max_depth=3, silent=1 \n",
      "[0]\tvalidation_0-auc:0.529008\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[1000]\tvalidation_0-auc:0.725039\n",
      "[1000]\tvalidation_0-auc:0.711252\n",
      "[2000]\tvalidation_0-auc:0.734203\n",
      "Stopping. Best iteration:\n",
      "[2440]\tvalidation_0-auc:0.739295\n",
      "\n",
      "[CV]  n_estimators=10000, objective=binary:logistic, learning_rate=0.03, max_depth=3, silent=1 - 5.7min\n",
      "[CV] n_estimators=10000, objective=binary:logistic, learning_rate=0.03, max_depth=3, silent=1 \n",
      "[0]\tvalidation_0-auc:0.547004\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[2000]\tvalidation_0-auc:0.720426\n",
      "Stopping. Best iteration:\n",
      "[2076]\tvalidation_0-auc:0.721187\n",
      "\n",
      "[CV]  n_estimators=10000, objective=binary:logistic, learning_rate=0.03, max_depth=3, silent=1 - 5.1min\n",
      "[CV] n_estimators=10000, objective=binary:logistic, learning_rate=0.03, max_depth=5, silent=1 \n",
      "[0]\tvalidation_0-auc:0.608486\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[1000]\tvalidation_0-auc:0.719023\n",
      "[2000]\tvalidation_0-auc:0.731353\n",
      "[1000]\tvalidation_0-auc:0.735936\n",
      "Stopping. Best iteration:\n",
      "[2489]\tvalidation_0-auc:0.734581\n",
      "\n",
      "[CV]  n_estimators=10000, objective=binary:logistic, learning_rate=0.03, max_depth=3, silent=1 - 6.3min\n",
      "[CV] n_estimators=10000, objective=binary:logistic, learning_rate=0.03, max_depth=5, silent=1 \n",
      "[0]\tvalidation_0-auc:0.577959\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1564]\tvalidation_0-auc:0.738337\n",
      "\n",
      "[CV]  n_estimators=10000, objective=binary:logistic, learning_rate=0.03, max_depth=5, silent=1 - 6.7min\n",
      "[CV] n_estimators=10000, objective=binary:logistic, learning_rate=0.03, max_depth=5, silent=1 \n",
      "[0]\tvalidation_0-auc:0.638069\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[1000]\tvalidation_0-auc:0.714059\n",
      "[1000]\tvalidation_0-auc:0.747485\n",
      "Stopping. Best iteration:\n",
      "[1333]\tvalidation_0-auc:0.714851\n",
      "\n",
      "[CV]  n_estimators=10000, objective=binary:logistic, learning_rate=0.03, max_depth=5, silent=1 - 5.6min\n",
      "[CV] n_estimators=10000, objective=binary:logistic, learning_rate=0.03, max_depth=5, silent=1 \n",
      "[0]\tvalidation_0-auc:0.61347\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1324]\tvalidation_0-auc:0.749041\n",
      "\n",
      "[CV]  n_estimators=10000, objective=binary:logistic, learning_rate=0.03, max_depth=5, silent=1 - 5.6min\n",
      "[CV] n_estimators=10000, objective=binary:logistic, learning_rate=0.03, max_depth=5, silent=1 \n",
      "[0]\tvalidation_0-auc:0.634673\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[777]\tvalidation_0-auc:0.731405\n",
      "\n",
      "[CV]  n_estimators=10000, objective=binary:logistic, learning_rate=0.03, max_depth=5, silent=1 - 3.5min\n",
      "[CV] n_estimators=10000, objective=binary:logistic, learning_rate=0.03, max_depth=7, silent=1 \n",
      "[0]\tvalidation_0-auc:0.656364\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[1000]\tvalidation_0-auc:0.740076\n",
      "Stopping. Best iteration:\n",
      "[1394]\tvalidation_0-auc:0.741496\n",
      "\n",
      "[CV]  n_estimators=10000, objective=binary:logistic, learning_rate=0.03, max_depth=5, silent=1 - 5.7min\n",
      "[CV] n_estimators=10000, objective=binary:logistic, learning_rate=0.03, max_depth=7, silent=1 \n",
      "[0]\tvalidation_0-auc:0.628367\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[1000]\tvalidation_0-auc:0.739379\n",
      "Stopping. Best iteration:\n",
      "[803]\tvalidation_0-auc:0.741424\n",
      "\n",
      "[CV]  n_estimators=10000, objective=binary:logistic, learning_rate=0.03, max_depth=7, silent=1 - 5.1min\n",
      "[CV] n_estimators=10000, objective=binary:logistic, learning_rate=0.03, max_depth=7, silent=1 \n",
      "[0]\tvalidation_0-auc:0.683078\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[521]\tvalidation_0-auc:0.719114\n",
      "\n",
      "[CV]  n_estimators=10000, objective=binary:logistic, learning_rate=0.03, max_depth=7, silent=1 - 3.6min\n",
      "[CV] n_estimators=10000, objective=binary:logistic, learning_rate=0.03, max_depth=7, silent=1 \n",
      "[0]\tvalidation_0-auc:0.643099\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[581]\tvalidation_0-auc:0.752064\n",
      "\n",
      "[CV]  n_estimators=10000, objective=binary:logistic, learning_rate=0.03, max_depth=7, silent=1 - 4.6min\n",
      "[CV] n_estimators=10000, objective=binary:logistic, learning_rate=0.03, max_depth=7, silent=1 \n",
      "[0]\tvalidation_0-auc:0.631997\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[399]\tvalidation_0-auc:0.738374\n",
      "\n",
      "[CV]  n_estimators=10000, objective=binary:logistic, learning_rate=0.03, max_depth=7, silent=1 - 5.5min\n",
      "[CV] n_estimators=10000, objective=binary:logistic, learning_rate=0.05, max_depth=3, silent=1 \n",
      "[0]\tvalidation_0-auc:0.513271\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[546]\tvalidation_0-auc:0.742238\n",
      "\n",
      "[CV]  n_estimators=10000, objective=binary:logistic, learning_rate=0.03, max_depth=7, silent=1 - 6.7min\n",
      "[CV] n_estimators=10000, objective=binary:logistic, learning_rate=0.05, max_depth=3, silent=1 \n",
      "[0]\tvalidation_0-auc:0.512725\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[1000]\tvalidation_0-auc:0.722471\n",
      "Stopping. Best iteration:\n",
      "[1691]\tvalidation_0-auc:0.732279\n",
      "\n",
      "[CV]  n_estimators=10000, objective=binary:logistic, learning_rate=0.05, max_depth=3, silent=1 - 5.3min\n",
      "[CV] n_estimators=10000, objective=binary:logistic, learning_rate=0.05, max_depth=3, silent=1 \n",
      "[0]\tvalidation_0-auc:0.593536\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[1000]\tvalidation_0-auc:0.705612\n",
      "Stopping. Best iteration:\n",
      "[1607]\tvalidation_0-auc:0.710054\n",
      "\n",
      "[CV]  n_estimators=10000, objective=binary:logistic, learning_rate=0.05, max_depth=3, silent=1 - 3.8min\n",
      "[CV] n_estimators=10000, objective=binary:logistic, learning_rate=0.05, max_depth=3, silent=1 \n",
      "[0]\tvalidation_0-auc:0.529008\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[1000]\tvalidation_0-auc:0.734757\n",
      "[1000]\tvalidation_0-auc:0.719423\n",
      "Stopping. Best iteration:\n",
      "[1755]\tvalidation_0-auc:0.744103\n",
      "\n",
      "[CV]  n_estimators=10000, objective=binary:logistic, learning_rate=0.05, max_depth=3, silent=1 - 4.2min\n",
      "[CV] n_estimators=10000, objective=binary:logistic, learning_rate=0.05, max_depth=3, silent=1 \n",
      "[0]\tvalidation_0-auc:0.547004\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[2000]\tvalidation_0-auc:0.72179\n",
      "Stopping. Best iteration:\n",
      "[1824]\tvalidation_0-auc:0.722519\n",
      "\n",
      "[CV]  n_estimators=10000, objective=binary:logistic, learning_rate=0.05, max_depth=3, silent=1 - 4.3min\n",
      "[CV] n_estimators=10000, objective=binary:logistic, learning_rate=0.05, max_depth=5, silent=1 \n",
      "[0]\tvalidation_0-auc:0.608486\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[1000]\tvalidation_0-auc:0.727258\n",
      "Stopping. Best iteration:\n",
      "[1619]\tvalidation_0-auc:0.734238\n",
      "\n",
      "[CV]  n_estimators=10000, objective=binary:logistic, learning_rate=0.05, max_depth=3, silent=1 - 3.9min\n",
      "[CV] n_estimators=10000, objective=binary:logistic, learning_rate=0.05, max_depth=5, silent=1 \n",
      "[0]\tvalidation_0-auc:0.577959\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[601]\tvalidation_0-auc:0.73702\n",
      "\n",
      "[CV]  n_estimators=10000, objective=binary:logistic, learning_rate=0.05, max_depth=5, silent=1 - 3.1min\n",
      "[CV] n_estimators=10000, objective=binary:logistic, learning_rate=0.05, max_depth=5, silent=1 \n",
      "[0]\tvalidation_0-auc:0.638069\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[560]\tvalidation_0-auc:0.715222\n",
      "\n",
      "[CV]  n_estimators=10000, objective=binary:logistic, learning_rate=0.05, max_depth=5, silent=1 - 3.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed: 132.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] n_estimators=10000, objective=binary:logistic, learning_rate=0.05, max_depth=5, silent=1 \n",
      "[0]\tvalidation_0-auc:0.61347\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[557]\tvalidation_0-auc:0.749785\n",
      "\n",
      "[CV]  n_estimators=10000, objective=binary:logistic, learning_rate=0.05, max_depth=5, silent=1 - 3.6min\n",
      "[CV] n_estimators=10000, objective=binary:logistic, learning_rate=0.05, max_depth=5, silent=1 \n",
      "[0]\tvalidation_0-auc:0.634673\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[684]\tvalidation_0-auc:0.732199\n",
      "\n",
      "[CV]  n_estimators=10000, objective=binary:logistic, learning_rate=0.05, max_depth=5, silent=1 - 3.6min\n",
      "[CV] n_estimators=10000, objective=binary:logistic, learning_rate=0.05, max_depth=7, silent=1 \n",
      "[0]\tvalidation_0-auc:0.656364\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[773]\tvalidation_0-auc:0.739917\n",
      "\n",
      "[CV]  n_estimators=10000, objective=binary:logistic, learning_rate=0.05, max_depth=5, silent=1 - 3.8min\n",
      "[CV] n_estimators=10000, objective=binary:logistic, learning_rate=0.05, max_depth=7, silent=1 \n",
      "[0]\tvalidation_0-auc:0.628367\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[411]\tvalidation_0-auc:0.742933\n",
      "\n",
      "[CV]  n_estimators=10000, objective=binary:logistic, learning_rate=0.05, max_depth=7, silent=1 - 3.1min\n",
      "[CV] n_estimators=10000, objective=binary:logistic, learning_rate=0.05, max_depth=7, silent=1 \n",
      "[0]\tvalidation_0-auc:0.683078\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[220]\tvalidation_0-auc:0.719773\n",
      "\n",
      "[CV]  n_estimators=10000, objective=binary:logistic, learning_rate=0.05, max_depth=7, silent=1 - 2.1min\n",
      "[CV] n_estimators=10000, objective=binary:logistic, learning_rate=0.05, max_depth=7, silent=1 \n",
      "[0]\tvalidation_0-auc:0.643099\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[251]\tvalidation_0-auc:0.73757\n",
      "\n",
      "[CV]  n_estimators=10000, objective=binary:logistic, learning_rate=0.05, max_depth=7, silent=1 - 2.3min\n",
      "[CV] n_estimators=10000, objective=binary:logistic, learning_rate=0.05, max_depth=7, silent=1 \n",
      "[0]\tvalidation_0-auc:0.631997\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[362]\tvalidation_0-auc:0.75222\n",
      "\n",
      "[CV]  n_estimators=10000, objective=binary:logistic, learning_rate=0.05, max_depth=7, silent=1 - 2.8min\n",
      "Stopping. Best iteration:\n",
      "[519]\tvalidation_0-auc:0.741781\n",
      "\n",
      "[CV]  n_estimators=10000, objective=binary:logistic, learning_rate=0.05, max_depth=7, silent=1 - 3.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed: 144.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.659962\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[1000]\tvalidation_0-auc:0.741186\n",
      "Stopping. Best iteration:\n",
      "[1313]\tvalidation_0-auc:0.743315\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1),\n",
       "       fit_params={'eval_set': [[array([[-0.79214, -0.86342, ..., -0.471  ,  0.54577],\n",
       "       [-0.71002, -1.34797, ..., -0.48109,  0.98213],\n",
       "       ...,\n",
       "       [-0.27992, -1.74503, ..., -0.55762, -0.31676],\n",
       "       [-0.24504, -0.71002, ..., -0.49514, -0.19996]]), array([1, 1, ..., 1, 1])]], 'early_stopping_rounds': 200, 'eval_metric': 'auc', 'verbose': 1000},\n",
       "       iid=True, n_jobs=-1,\n",
       "       param_grid={'objective': ['binary:logistic'], 'n_estimators': [10000], 'learning_rate': [0.01, 0.03, 0.05], 'max_depth': [3, 5, 7], 'silent': [1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "clf_detailed.fit(x_train, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>objective</th>\n",
       "      <th>score</th>\n",
       "      <th>silent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.720398</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.719755</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.719026</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>7</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.717597</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>7</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.717589</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "      <td>3</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.717567</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.716093</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.715624</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.714788</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3</td>\n",
       "      <td>0.03</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.705348</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3</td>\n",
       "      <td>0.03</td>\n",
       "      <td>7</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.704752</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.703532</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>7</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.703277</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.703057</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.702988</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>0.03</td>\n",
       "      <td>3</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.701880</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.701428</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.700179</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.674184</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4</td>\n",
       "      <td>0.03</td>\n",
       "      <td>7</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.673769</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "      <td>0.03</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.673065</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.672542</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.672294</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.672117</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>0.03</td>\n",
       "      <td>3</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.671960</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>7</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.670347</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.669560</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.656554</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.655540</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.655158</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.654333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.654076</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>7</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.653983</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>7</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.653032</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>3</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.652753</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>0.03</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.649564</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.648473</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>7</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.647929</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>0.03</td>\n",
       "      <td>7</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.647351</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>0.03</td>\n",
       "      <td>3</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.647228</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.646838</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.646619</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.646212</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.644753</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.548866</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fold  learning_rate  max_depth  n_estimators        objective     score  \\\n",
       "21     1           0.03          5         10000  binary:logistic  0.720398   \n",
       "36     1           0.05          5         10000  binary:logistic  0.719755   \n",
       "31     1           0.05          3         10000  binary:logistic  0.719026   \n",
       "41     1           0.05          7         10000  binary:logistic  0.717597   \n",
       "26     1           0.03          7         10000  binary:logistic  0.717589   \n",
       "16     1           0.03          3         10000  binary:logistic  0.717567   \n",
       "6      1           0.01          5         10000  binary:logistic  0.716093   \n",
       "1      1           0.01          3         10000  binary:logistic  0.715624   \n",
       "11     1           0.01          7         10000  binary:logistic  0.714788   \n",
       "23     3           0.03          5         10000  binary:logistic  0.705348   \n",
       "28     3           0.03          7         10000  binary:logistic  0.704752   \n",
       "38     3           0.05          5         10000  binary:logistic  0.703532   \n",
       "43     3           0.05          7         10000  binary:logistic  0.703277   \n",
       "13     3           0.01          7         10000  binary:logistic  0.703057   \n",
       "8      3           0.01          5         10000  binary:logistic  0.702988   \n",
       "18     3           0.03          3         10000  binary:logistic  0.701880   \n",
       "3      3           0.01          3         10000  binary:logistic  0.701428   \n",
       "33     3           0.05          3         10000  binary:logistic  0.700179   \n",
       "39     4           0.05          5         10000  binary:logistic  0.674184   \n",
       "29     4           0.03          7         10000  binary:logistic  0.673769   \n",
       "24     4           0.03          5         10000  binary:logistic  0.673065   \n",
       "34     4           0.05          3         10000  binary:logistic  0.672542   \n",
       "9      4           0.01          5         10000  binary:logistic  0.672294   \n",
       "14     4           0.01          7         10000  binary:logistic  0.672117   \n",
       "19     4           0.03          3         10000  binary:logistic  0.671960   \n",
       "44     4           0.05          7         10000  binary:logistic  0.670347   \n",
       "4      4           0.01          3         10000  binary:logistic  0.669560   \n",
       "10     0           0.01          7         10000  binary:logistic  0.656554   \n",
       "20     0           0.03          5         10000  binary:logistic  0.655540   \n",
       "5      0           0.01          5         10000  binary:logistic  0.655158   \n",
       "35     0           0.05          5         10000  binary:logistic  0.654333   \n",
       "30     0           0.05          3         10000  binary:logistic  0.654076   \n",
       "40     0           0.05          7         10000  binary:logistic  0.653983   \n",
       "25     0           0.03          7         10000  binary:logistic  0.653032   \n",
       "15     0           0.03          3         10000  binary:logistic  0.652753   \n",
       "22     2           0.03          5         10000  binary:logistic  0.649564   \n",
       "32     2           0.05          3         10000  binary:logistic  0.648473   \n",
       "42     2           0.05          7         10000  binary:logistic  0.647929   \n",
       "27     2           0.03          7         10000  binary:logistic  0.647351   \n",
       "17     2           0.03          3         10000  binary:logistic  0.647228   \n",
       "12     2           0.01          7         10000  binary:logistic  0.646838   \n",
       "7      2           0.01          5         10000  binary:logistic  0.646619   \n",
       "37     2           0.05          5         10000  binary:logistic  0.646212   \n",
       "0      0           0.01          3         10000  binary:logistic  0.644753   \n",
       "2      2           0.01          3         10000  binary:logistic  0.548866   \n",
       "\n",
       "    silent  \n",
       "21       1  \n",
       "36       1  \n",
       "31       1  \n",
       "41       1  \n",
       "26       1  \n",
       "16       1  \n",
       "6        1  \n",
       "1        1  \n",
       "11       1  \n",
       "23       1  \n",
       "28       1  \n",
       "38       1  \n",
       "43       1  \n",
       "13       1  \n",
       "8        1  \n",
       "18       1  \n",
       "3        1  \n",
       "33       1  \n",
       "39       1  \n",
       "29       1  \n",
       "24       1  \n",
       "34       1  \n",
       "9        1  \n",
       "14       1  \n",
       "19       1  \n",
       "44       1  \n",
       "4        1  \n",
       "10       1  \n",
       "20       1  \n",
       "5        1  \n",
       "35       1  \n",
       "30       1  \n",
       "40       1  \n",
       "25       1  \n",
       "15       1  \n",
       "22       1  \n",
       "32       1  \n",
       "42       1  \n",
       "27       1  \n",
       "17       1  \n",
       "12       1  \n",
       "7        1  \n",
       "37       1  \n",
       "0        1  \n",
       "2        1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Found online function to change format output of grid_scores_ into pandas df\n",
    "def grid_scores_to_df(grid_scores):\n",
    "    \"\"\"\n",
    "    Convert a sklearn.grid_search.GridSearchCV.grid_scores_ attribute to a tidy\n",
    "    pandas DataFrame where each row is a hyperparameter-fold combinatination.\n",
    "    \"\"\"\n",
    "    rows = list()\n",
    "    for grid_score in grid_scores:\n",
    "        for fold, score in enumerate(grid_score.cv_validation_scores):\n",
    "            row = grid_score.parameters.copy()\n",
    "            row['fold'] = fold\n",
    "            row['score'] = score\n",
    "            rows.append(row)\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df\n",
    "\n",
    "# Print grid_scores_\n",
    "grid_scores_to_df(clf_detailed.grid_scores_).sort_values('score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.680783001862\n",
      "{'n_estimators': 10000, 'objective': 'binary:logistic', 'learning_rate': 0.03, 'max_depth': 5, 'silent': 1}\n"
     ]
    }
   ],
   "source": [
    "print clf_detailed.best_score_\n",
    "print clf_detailed.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we weren't able to really improve our model any more here. _**That code above took 2.5 hours to run by the way on my 2-core Macbook Pro**_. A lot of time for no gain in accuracy, but hey, we had to do it to find out!\n",
    "\n",
    "Note that the errors that the test errors we saw while we were training the xgboost model _**are different than the test errors we are getting from the averaged CV results of clf\\_detailed.grid\\_scores\\_ and clf\\_detailed.best\\_score\\_**. This is because, again, the test sets we are using in these cases are different! When we are training the model, we are using a consistent test set (10% of the training samples) for early stopping purposes. When we read the parameters of clf\\_detailed, we are using the randomized 5-fold CV test set average produced by GridSearchCV.\n",
    "\n",
    "It looks like a depth of 5 for trees are a pretty good choice, and even though this model selected 0.03 as a learning rate, it's actually worse than the model we trained before with 0.05 learning rate, so I'll just keep the parameters from our previous model: A learning rate of 0.05 and tree depth of 5.\n",
    "\n",
    "There is _**one more thing**_ that I'd like to tweak, and that's tree subsampling. The _**subsample**_ parameter controls the percentage of training samples used in each tree, and the _**colsample\\_bytree**_ parameter controls the percentage of features used in each tree. These can help prevent overfitting and decrease the out-of-sample error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "xgb_model_subsample = xgb.XGBClassifier()\n",
    "\n",
    "# Set parameters (for GridSearchCV, every value must be in a list, even if there is only 1 value we want to test)\n",
    "param_subsample = {\n",
    "    'max_depth': [5],\n",
    "    'learning_rate': [0.05],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9],\n",
    "    'objective': ['binary:logistic'],\n",
    "    'silent': [1],\n",
    "    'n_estimators': [10000]\n",
    "}\n",
    "\n",
    "fit_params_subsample = {\n",
    "    'early_stopping_rounds': 200,\n",
    "    'eval_metric': 'auc',\n",
    "    'eval_set': [[x_test, y_test_encoded]],\n",
    "    'verbose': 500\n",
    "}\n",
    "\n",
    "# Set up grid search\n",
    "clf_subsample = GridSearchCV(\n",
    "    xgb_model_subsample,\n",
    "    param_subsample,\n",
    "    fit_params = fit_params_subsample,\n",
    "    n_jobs = -1,\n",
    "    cv = 5, \n",
    "    scoring = 'roc_auc',\n",
    "    verbose = 2,\n",
    "    refit = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] colsample_bytree=0.7, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.7, objective=binary:logistic, max_depth=5 \n",
      "[CV] colsample_bytree=0.7, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.7, objective=binary:logistic, max_depth=5 \n",
      "[0]\tvalidation_0-auc:0.626433\n",
      "[0]\tvalidation_0-auc:0.621493\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[500]\tvalidation_0-auc:0.742467\n",
      "[500]\tvalidation_0-auc:0.719881\n",
      "Stopping. Best iteration:\n",
      "[522]\tvalidation_0-auc:0.743337\n",
      "\n",
      "[CV]  colsample_bytree=0.7, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.7, objective=binary:logistic, max_depth=5 - 2.1min\n",
      "[CV] colsample_bytree=0.7, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.7, objective=binary:logistic, max_depth=5 \n",
      "[0]\tvalidation_0-auc:0.640332\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[557]\tvalidation_0-auc:0.721212\n",
      "\n",
      "[CV]  colsample_bytree=0.7, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.7, objective=binary:logistic, max_depth=5 - 2.2min\n",
      "[CV] colsample_bytree=0.7, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.7, objective=binary:logistic, max_depth=5 \n",
      "[0]\tvalidation_0-auc:0.651084\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[500]\tvalidation_0-auc:0.752411\n",
      "[500]\tvalidation_0-auc:0.73657\n",
      "Stopping. Best iteration:\n",
      "[429]\tvalidation_0-auc:0.738325\n",
      "\n",
      "Stopping. Best iteration:\n",
      "[468]\tvalidation_0-auc:0.752967\n",
      "\n",
      "[CV]  colsample_bytree=0.7, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.7, objective=binary:logistic, max_depth=5 - 1.7min\n",
      "[CV]  colsample_bytree=0.7, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.7, objective=binary:logistic, max_depth=5 - 1.9min\n",
      "[CV] colsample_bytree=0.7, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.7, objective=binary:logistic, max_depth=5 \n",
      "[CV] colsample_bytree=0.7, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.8, objective=binary:logistic, max_depth=5 \n",
      "[0]\tvalidation_0-auc:0.63271\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[0]\tvalidation_0-auc:0.628653\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[500]\tvalidation_0-auc:0.742516\n",
      "[500]\tvalidation_0-auc:0.740023\n",
      "Stopping. Best iteration:\n",
      "[400]\tvalidation_0-auc:0.743097\n",
      "\n",
      "[CV]  colsample_bytree=0.7, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.7, objective=binary:logistic, max_depth=5 - 1.6min\n",
      "[CV] colsample_bytree=0.7, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.8, objective=binary:logistic, max_depth=5 \n",
      "[0]\tvalidation_0-auc:0.630049\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[602]\tvalidation_0-auc:0.741323\n",
      "\n",
      "[CV]  colsample_bytree=0.7, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.8, objective=binary:logistic, max_depth=5 - 2.3min\n",
      "[CV] colsample_bytree=0.7, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.8, objective=binary:logistic, max_depth=5 \n",
      "[0]\tvalidation_0-auc:0.64601\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[500]\tvalidation_0-auc:0.717947\n",
      "[500]\tvalidation_0-auc:0.752027\n",
      "Stopping. Best iteration:\n",
      "[542]\tvalidation_0-auc:0.718471\n",
      "\n",
      "[CV]  colsample_bytree=0.7, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.8, objective=binary:logistic, max_depth=5 - 2.1min\n",
      "[CV] colsample_bytree=0.7, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.8, objective=binary:logistic, max_depth=5 \n",
      "[0]\tvalidation_0-auc:0.653424\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[498]\tvalidation_0-auc:0.752224\n",
      "\n",
      "[CV]  colsample_bytree=0.7, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.8, objective=binary:logistic, max_depth=5 - 1.9min\n",
      "[CV] colsample_bytree=0.7, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.8, objective=binary:logistic, max_depth=5 \n",
      "[0]\tvalidation_0-auc:0.634374\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[500]\tvalidation_0-auc:0.733748\n",
      "Stopping. Best iteration:\n",
      "[305]\tvalidation_0-auc:0.73527\n",
      "\n",
      "[CV]  colsample_bytree=0.7, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.8, objective=binary:logistic, max_depth=5 - 1.6min\n",
      "[CV] colsample_bytree=0.7, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.9, objective=binary:logistic, max_depth=5 \n",
      "[0]\tvalidation_0-auc:0.630429\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[500]\tvalidation_0-auc:0.742126\n",
      "Stopping. Best iteration:\n",
      "[613]\tvalidation_0-auc:0.743031\n",
      "\n",
      "[CV]  colsample_bytree=0.7, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.8, objective=binary:logistic, max_depth=5 - 2.7min\n",
      "[CV] colsample_bytree=0.7, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.9, objective=binary:logistic, max_depth=5 \n",
      "[0]\tvalidation_0-auc:0.634551\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[500]\tvalidation_0-auc:0.739232\n",
      "Stopping. Best iteration:\n",
      "[637]\tvalidation_0-auc:0.740559\n",
      "\n",
      "[CV]  colsample_bytree=0.7, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.9, objective=binary:logistic, max_depth=5 - 2.5min\n",
      "[CV] colsample_bytree=0.7, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.9, objective=binary:logistic, max_depth=5 \n",
      "[0]\tvalidation_0-auc:0.643621\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[500]\tvalidation_0-auc:0.71715\n",
      "Stopping. Best iteration:\n",
      "[391]\tvalidation_0-auc:0.718961\n",
      "\n",
      "[CV]  colsample_bytree=0.7, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.9, objective=binary:logistic, max_depth=5 - 1.6min\n",
      "[CV] colsample_bytree=0.7, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.9, objective=binary:logistic, max_depth=5 \n",
      "[0]\tvalidation_0-auc:0.648771\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[500]\tvalidation_0-auc:0.750031\n",
      "[500]\tvalidation_0-auc:0.732865\n",
      "Stopping. Best iteration:\n",
      "[797]\tvalidation_0-auc:0.751822\n",
      "\n",
      "[CV]  colsample_bytree=0.7, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.9, objective=binary:logistic, max_depth=5 - 2.8min\n",
      "[CV] colsample_bytree=0.7, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.9, objective=binary:logistic, max_depth=5 \n",
      "[0]\tvalidation_0-auc:0.639991\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[545]\tvalidation_0-auc:0.733597\n",
      "\n",
      "[CV]  colsample_bytree=0.7, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.9, objective=binary:logistic, max_depth=5 - 3.1min\n",
      "[CV] colsample_bytree=0.8, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.7, objective=binary:logistic, max_depth=5 \n",
      "[0]\tvalidation_0-auc:0.532444\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[500]\tvalidation_0-auc:0.741197\n",
      "[500]\tvalidation_0-auc:0.73913\n",
      "Stopping. Best iteration:\n",
      "[663]\tvalidation_0-auc:0.743253\n",
      "\n",
      "[CV]  colsample_bytree=0.7, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.9, objective=binary:logistic, max_depth=5 - 2.8min\n",
      "[CV] colsample_bytree=0.8, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.7, objective=binary:logistic, max_depth=5 \n",
      "[0]\tvalidation_0-auc:0.628088\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[580]\tvalidation_0-auc:0.739775\n",
      "\n",
      "[CV]  colsample_bytree=0.8, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.7, objective=binary:logistic, max_depth=5 - 2.6min\n",
      "[CV] colsample_bytree=0.8, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.7, objective=binary:logistic, max_depth=5 \n",
      "[0]\tvalidation_0-auc:0.640148\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[290]\tvalidation_0-auc:0.72124\n",
      "\n",
      "[CV]  colsample_bytree=0.8, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.7, objective=binary:logistic, max_depth=5 - 1.5min\n",
      "[CV] colsample_bytree=0.8, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.7, objective=binary:logistic, max_depth=5 \n",
      "[0]\tvalidation_0-auc:0.614992\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[500]\tvalidation_0-auc:0.752026\n",
      "Stopping. Best iteration:\n",
      "[522]\tvalidation_0-auc:0.752397\n",
      "\n",
      "[CV]  colsample_bytree=0.8, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.7, objective=binary:logistic, max_depth=5 - 2.1min\n",
      "[CV] colsample_bytree=0.8, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.7, objective=binary:logistic, max_depth=5 \n",
      "[0]\tvalidation_0-auc:0.630985\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[500]\tvalidation_0-auc:0.736992\n",
      "Stopping. Best iteration:\n",
      "[358]\tvalidation_0-auc:0.737188\n",
      "\n",
      "[CV]  colsample_bytree=0.8, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.7, objective=binary:logistic, max_depth=5 - 1.6min\n",
      "[CV] colsample_bytree=0.8, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.8, objective=binary:logistic, max_depth=5 \n",
      "[0]\tvalidation_0-auc:0.603741\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[500]\tvalidation_0-auc:0.740503\n",
      "Stopping. Best iteration:\n",
      "[398]\tvalidation_0-auc:0.742338\n",
      "\n",
      "[500]\tvalidation_0-auc:0.741412\n",
      "[CV]  colsample_bytree=0.8, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.7, objective=binary:logistic, max_depth=5 - 1.7min\n",
      "[CV] colsample_bytree=0.8, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.8, objective=binary:logistic, max_depth=5 \n",
      "[0]\tvalidation_0-auc:0.577149\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[468]\tvalidation_0-auc:0.742014\n",
      "\n",
      "[CV]  colsample_bytree=0.8, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.8, objective=binary:logistic, max_depth=5 - 1.9min\n",
      "[CV] colsample_bytree=0.8, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.8, objective=binary:logistic, max_depth=5 \n",
      "[0]\tvalidation_0-auc:0.640251\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[500]\tvalidation_0-auc:0.718677\n",
      "[500]\tvalidation_0-auc:0.752883\n",
      "Stopping. Best iteration:\n",
      "[381]\tvalidation_0-auc:0.719118\n",
      "\n",
      "[CV]  colsample_bytree=0.8, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.8, objective=binary:logistic, max_depth=5 - 2.2min\n",
      "[CV] colsample_bytree=0.8, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.8, objective=binary:logistic, max_depth=5 \n",
      "[0]\tvalidation_0-auc:0.615868\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[550]\tvalidation_0-auc:0.753581\n",
      "\n",
      "[CV]  colsample_bytree=0.8, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.8, objective=binary:logistic, max_depth=5 - 2.6min\n",
      "[CV] colsample_bytree=0.8, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.8, objective=binary:logistic, max_depth=5 \n",
      "[0]\tvalidation_0-auc:0.629543\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[500]\tvalidation_0-auc:0.734682\n",
      "Stopping. Best iteration:\n",
      "[362]\tvalidation_0-auc:0.735129\n",
      "\n",
      "[CV]  colsample_bytree=0.8, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.8, objective=binary:logistic, max_depth=5 - 2.5min\n",
      "[CV] colsample_bytree=0.8, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.9, objective=binary:logistic, max_depth=5 \n",
      "[0]\tvalidation_0-auc:0.609021\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[500]\tvalidation_0-auc:0.740219\n",
      "[500]\tvalidation_0-auc:0.738144\n",
      "Stopping. Best iteration:\n",
      "[729]\tvalidation_0-auc:0.742077\n",
      "\n",
      "[CV]  colsample_bytree=0.8, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.8, objective=binary:logistic, max_depth=5 - 3.3min\n",
      "[CV] colsample_bytree=0.8, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.9, objective=binary:logistic, max_depth=5 \n",
      "[0]\tvalidation_0-auc:0.578738\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[732]\tvalidation_0-auc:0.740495\n",
      "\n",
      "[CV]  colsample_bytree=0.8, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.9, objective=binary:logistic, max_depth=5 - 2.7min\n",
      "[CV] colsample_bytree=0.8, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.9, objective=binary:logistic, max_depth=5 \n",
      "[0]\tvalidation_0-auc:0.637665\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[500]\tvalidation_0-auc:0.718595\n",
      "Stopping. Best iteration:\n",
      "[369]\tvalidation_0-auc:0.720238\n",
      "\n",
      "[CV]  colsample_bytree=0.8, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.9, objective=binary:logistic, max_depth=5 - 1.7min\n",
      "[CV] colsample_bytree=0.8, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.9, objective=binary:logistic, max_depth=5 \n",
      "[0]\tvalidation_0-auc:0.613573\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[500]\tvalidation_0-auc:0.735099\n",
      "[500]\tvalidation_0-auc:0.751294\n",
      "Stopping. Best iteration:\n",
      "[518]\tvalidation_0-auc:0.735194\n",
      "\n",
      "[CV]  colsample_bytree=0.8, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.9, objective=binary:logistic, max_depth=5 - 2.1min\n",
      "[CV] colsample_bytree=0.8, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.9, objective=binary:logistic, max_depth=5 \n",
      "[0]\tvalidation_0-auc:0.613274\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[598]\tvalidation_0-auc:0.752121\n",
      "\n",
      "[CV]  colsample_bytree=0.8, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.9, objective=binary:logistic, max_depth=5 - 3.3min\n",
      "[CV] colsample_bytree=0.9, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.7, objective=binary:logistic, max_depth=5 \n",
      "[0]\tvalidation_0-auc:0.531802\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[500]\tvalidation_0-auc:0.740434\n",
      "[500]\tvalidation_0-auc:0.740888\n",
      "Stopping. Best iteration:\n",
      "[758]\tvalidation_0-auc:0.741949\n",
      "\n",
      "[CV]  colsample_bytree=0.8, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.9, objective=binary:logistic, max_depth=5 - 2.8min\n",
      "[CV] colsample_bytree=0.9, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.7, objective=binary:logistic, max_depth=5 \n",
      "[0]\tvalidation_0-auc:0.628048\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[525]\tvalidation_0-auc:0.740912\n",
      "\n",
      "[CV]  colsample_bytree=0.9, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.7, objective=binary:logistic, max_depth=5 - 2.3min\n",
      "[CV] colsample_bytree=0.9, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.7, objective=binary:logistic, max_depth=5 \n",
      "[0]\tvalidation_0-auc:0.642379\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[500]\tvalidation_0-auc:0.718635\n",
      "[500]\tvalidation_0-auc:0.754403\n",
      "Stopping. Best iteration:\n",
      "[454]\tvalidation_0-auc:0.719811\n",
      "\n",
      "[CV]  colsample_bytree=0.9, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.7, objective=binary:logistic, max_depth=5 - 2.0min\n",
      "[CV] colsample_bytree=0.9, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.7, objective=binary:logistic, max_depth=5 \n",
      "[0]\tvalidation_0-auc:0.61675\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[563]\tvalidation_0-auc:0.754659\n",
      "\n",
      "[CV]  colsample_bytree=0.9, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.7, objective=binary:logistic, max_depth=5 - 2.4min\n",
      "[CV] colsample_bytree=0.9, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.7, objective=binary:logistic, max_depth=5 \n",
      "[0]\tvalidation_0-auc:0.630985\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[500]\tvalidation_0-auc:0.73542\n",
      "Stopping. Best iteration:\n",
      "[421]\tvalidation_0-auc:0.736701\n",
      "\n",
      "[500]\tvalidation_0-auc:0.741649\n",
      "[CV]  colsample_bytree=0.9, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.7, objective=binary:logistic, max_depth=5 - 1.9min\n",
      "[CV] colsample_bytree=0.9, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.8, objective=binary:logistic, max_depth=5 \n",
      "[0]\tvalidation_0-auc:0.601854\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[621]\tvalidation_0-auc:0.743325\n",
      "\n",
      "[CV]  colsample_bytree=0.9, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.7, objective=binary:logistic, max_depth=5 - 2.6min\n",
      "[CV] colsample_bytree=0.9, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.8, objective=binary:logistic, max_depth=5 \n",
      "[0]\tvalidation_0-auc:0.577032\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[500]\tvalidation_0-auc:0.741262\n",
      "Stopping. Best iteration:\n",
      "[501]\tvalidation_0-auc:0.741285\n",
      "\n",
      "[CV]  colsample_bytree=0.9, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.8, objective=binary:logistic, max_depth=5 - 2.2min\n",
      "[CV] colsample_bytree=0.9, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.8, objective=binary:logistic, max_depth=5 \n",
      "[0]\tvalidation_0-auc:0.636701\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[500]\tvalidation_0-auc:0.719984\n",
      "Stopping. Best iteration:\n",
      "[397]\tvalidation_0-auc:0.720948\n",
      "\n",
      "[CV]  colsample_bytree=0.9, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.8, objective=binary:logistic, max_depth=5 - 1.9min\n",
      "[CV] colsample_bytree=0.9, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.8, objective=binary:logistic, max_depth=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed: 42.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.61556\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[500]\tvalidation_0-auc:0.752751\n",
      "[500]\tvalidation_0-auc:0.732734\n",
      "Stopping. Best iteration:\n",
      "[553]\tvalidation_0-auc:0.753145\n",
      "\n",
      "[CV]  colsample_bytree=0.9, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.8, objective=binary:logistic, max_depth=5 - 2.4min\n",
      "[CV] colsample_bytree=0.9, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.8, objective=binary:logistic, max_depth=5 \n",
      "[0]\tvalidation_0-auc:0.629543\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[367]\tvalidation_0-auc:0.733894\n",
      "\n",
      "[CV]  colsample_bytree=0.9, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.8, objective=binary:logistic, max_depth=5 - 1.8min\n",
      "[CV] colsample_bytree=0.9, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.9, objective=binary:logistic, max_depth=5 \n",
      "[0]\tvalidation_0-auc:0.607452\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[500]\tvalidation_0-auc:0.742291\n",
      "[500]\tvalidation_0-auc:0.739158\n",
      "Stopping. Best iteration:\n",
      "[484]\tvalidation_0-auc:0.739365\n",
      "\n",
      "[CV]  colsample_bytree=0.9, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.9, objective=binary:logistic, max_depth=5 - 2.2min\n",
      "[CV] colsample_bytree=0.9, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.9, objective=binary:logistic, max_depth=5 \n",
      "[0]\tvalidation_0-auc:0.578702\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[718]\tvalidation_0-auc:0.744373\n",
      "\n",
      "[CV]  colsample_bytree=0.9, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.8, objective=binary:logistic, max_depth=5 - 2.9min\n",
      "[CV] colsample_bytree=0.9, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.9, objective=binary:logistic, max_depth=5 \n",
      "[0]\tvalidation_0-auc:0.639994\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[500]\tvalidation_0-auc:0.715133\n",
      "Stopping. Best iteration:\n",
      "[408]\tvalidation_0-auc:0.716178\n",
      "\n",
      "[CV]  colsample_bytree=0.9, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.9, objective=binary:logistic, max_depth=5 - 2.0min\n",
      "[CV] colsample_bytree=0.9, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.9, objective=binary:logistic, max_depth=5 \n",
      "[0]\tvalidation_0-auc:0.614972\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[500]\tvalidation_0-auc:0.751949\n",
      "Stopping. Best iteration:\n",
      "[488]\tvalidation_0-auc:0.752273\n",
      "\n",
      "[CV]  colsample_bytree=0.9, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.9, objective=binary:logistic, max_depth=5 - 2.3min\n",
      "[CV] colsample_bytree=0.9, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.9, objective=binary:logistic, max_depth=5 \n",
      "[0]\tvalidation_0-auc:0.613407\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[500]\tvalidation_0-auc:0.733043\n",
      "Stopping. Best iteration:\n",
      "[549]\tvalidation_0-auc:0.73361\n",
      "\n",
      "[CV]  colsample_bytree=0.9, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.9, objective=binary:logistic, max_depth=5 - 2.5min\n",
      "[500]\tvalidation_0-auc:0.740525\n",
      "Stopping. Best iteration:\n",
      "[708]\tvalidation_0-auc:0.742412\n",
      "\n",
      "[CV]  colsample_bytree=0.9, silent=1, learning_rate=0.05, n_estimators=10000, subsample=0.9, objective=binary:logistic, max_depth=5 - 3.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed: 51.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.573795\n",
      "Will train until validation_0-auc hasn't improved in 200 rounds.\n",
      "[500]\tvalidation_0-auc:0.743654\n",
      "Stopping. Best iteration:\n",
      "[477]\tvalidation_0-auc:0.743996\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1),\n",
       "       fit_params={'eval_set': [[array([[-0.79214, -0.86342, ..., -0.471  ,  0.54577],\n",
       "       [-0.71002, -1.34797, ..., -0.48109,  0.98213],\n",
       "       ...,\n",
       "       [-0.27992, -1.74503, ..., -0.55762, -0.31676],\n",
       "       [-0.24504, -0.71002, ..., -0.49514, -0.19996]]), array([1, 1, ..., 1, 1])]], 'early_stopping_rounds': 200, 'eval_metric': 'auc', 'verbose': 500},\n",
       "       iid=True, n_jobs=-1,\n",
       "       param_grid={'colsample_bytree': [0.7, 0.8, 0.9], 'silent': [1], 'learning_rate': [0.05], 'n_estimators': [10000], 'subsample': [0.7, 0.8, 0.9], 'objective': ['binary:logistic'], 'max_depth': [5]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "clf_subsample.fit(x_train, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>fold</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>objective</th>\n",
       "      <th>score</th>\n",
       "      <th>silent</th>\n",
       "      <th>subsample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.725850</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.725828</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.725306</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.724314</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.723708</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.723655</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.722275</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.721082</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.721046</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.707462</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.706825</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.706708</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.706461</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.706393</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.706389</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.705782</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.705648</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.705341</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.679983</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.679365</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.678641</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.677164</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.677005</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.676666</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.675797</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.675600</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.674420</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.659766</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.659228</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.658933</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.658304</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.658093</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.658056</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.657959</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.657692</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.655371</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.653512</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.651777</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.651701</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.651190</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.650749</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.650721</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.650160</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.649803</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>10000</td>\n",
       "      <td>binary:logistic</td>\n",
       "      <td>0.648361</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    colsample_bytree  fold  learning_rate  max_depth  n_estimators  \\\n",
       "31               0.9     1           0.05          5         10000   \n",
       "1                0.7     1           0.05          5         10000   \n",
       "16               0.8     1           0.05          5         10000   \n",
       "6                0.7     1           0.05          5         10000   \n",
       "21               0.8     1           0.05          5         10000   \n",
       "36               0.9     1           0.05          5         10000   \n",
       "26               0.8     1           0.05          5         10000   \n",
       "41               0.9     1           0.05          5         10000   \n",
       "11               0.7     1           0.05          5         10000   \n",
       "38               0.9     3           0.05          5         10000   \n",
       "3                0.7     3           0.05          5         10000   \n",
       "18               0.8     3           0.05          5         10000   \n",
       "8                0.7     3           0.05          5         10000   \n",
       "23               0.8     3           0.05          5         10000   \n",
       "33               0.9     3           0.05          5         10000   \n",
       "43               0.9     3           0.05          5         10000   \n",
       "28               0.8     3           0.05          5         10000   \n",
       "13               0.7     3           0.05          5         10000   \n",
       "19               0.8     4           0.05          5         10000   \n",
       "9                0.7     4           0.05          5         10000   \n",
       "4                0.7     4           0.05          5         10000   \n",
       "14               0.7     4           0.05          5         10000   \n",
       "34               0.9     4           0.05          5         10000   \n",
       "24               0.8     4           0.05          5         10000   \n",
       "44               0.9     4           0.05          5         10000   \n",
       "39               0.9     4           0.05          5         10000   \n",
       "29               0.8     4           0.05          5         10000   \n",
       "20               0.8     0           0.05          5         10000   \n",
       "0                0.7     0           0.05          5         10000   \n",
       "35               0.9     0           0.05          5         10000   \n",
       "30               0.9     0           0.05          5         10000   \n",
       "15               0.8     0           0.05          5         10000   \n",
       "5                0.7     0           0.05          5         10000   \n",
       "40               0.9     0           0.05          5         10000   \n",
       "10               0.7     0           0.05          5         10000   \n",
       "25               0.8     0           0.05          5         10000   \n",
       "32               0.9     2           0.05          5         10000   \n",
       "7                0.7     2           0.05          5         10000   \n",
       "22               0.8     2           0.05          5         10000   \n",
       "37               0.9     2           0.05          5         10000   \n",
       "2                0.7     2           0.05          5         10000   \n",
       "17               0.8     2           0.05          5         10000   \n",
       "27               0.8     2           0.05          5         10000   \n",
       "42               0.9     2           0.05          5         10000   \n",
       "12               0.7     2           0.05          5         10000   \n",
       "\n",
       "          objective     score  silent  subsample  \n",
       "31  binary:logistic  0.725850       1        0.7  \n",
       "1   binary:logistic  0.725828       1        0.7  \n",
       "16  binary:logistic  0.725306       1        0.7  \n",
       "6   binary:logistic  0.724314       1        0.8  \n",
       "21  binary:logistic  0.723708       1        0.8  \n",
       "36  binary:logistic  0.723655       1        0.8  \n",
       "26  binary:logistic  0.722275       1        0.9  \n",
       "41  binary:logistic  0.721082       1        0.9  \n",
       "11  binary:logistic  0.721046       1        0.9  \n",
       "38  binary:logistic  0.707462       1        0.8  \n",
       "3   binary:logistic  0.706825       1        0.7  \n",
       "18  binary:logistic  0.706708       1        0.7  \n",
       "8   binary:logistic  0.706461       1        0.8  \n",
       "23  binary:logistic  0.706393       1        0.8  \n",
       "33  binary:logistic  0.706389       1        0.7  \n",
       "43  binary:logistic  0.705782       1        0.9  \n",
       "28  binary:logistic  0.705648       1        0.9  \n",
       "13  binary:logistic  0.705341       1        0.9  \n",
       "19  binary:logistic  0.679983       1        0.7  \n",
       "9   binary:logistic  0.679365       1        0.8  \n",
       "4   binary:logistic  0.678641       1        0.7  \n",
       "14  binary:logistic  0.677164       1        0.9  \n",
       "34  binary:logistic  0.677005       1        0.7  \n",
       "24  binary:logistic  0.676666       1        0.8  \n",
       "44  binary:logistic  0.675797       1        0.9  \n",
       "39  binary:logistic  0.675600       1        0.8  \n",
       "29  binary:logistic  0.674420       1        0.9  \n",
       "20  binary:logistic  0.659766       1        0.8  \n",
       "0   binary:logistic  0.659228       1        0.7  \n",
       "35  binary:logistic  0.658933       1        0.8  \n",
       "30  binary:logistic  0.658304       1        0.7  \n",
       "15  binary:logistic  0.658093       1        0.7  \n",
       "5   binary:logistic  0.658056       1        0.8  \n",
       "40  binary:logistic  0.657959       1        0.9  \n",
       "10  binary:logistic  0.657692       1        0.9  \n",
       "25  binary:logistic  0.655371       1        0.9  \n",
       "32  binary:logistic  0.653512       1        0.7  \n",
       "7   binary:logistic  0.651777       1        0.8  \n",
       "22  binary:logistic  0.651701       1        0.8  \n",
       "37  binary:logistic  0.651190       1        0.8  \n",
       "2   binary:logistic  0.650749       1        0.7  \n",
       "17  binary:logistic  0.650721       1        0.7  \n",
       "27  binary:logistic  0.650160       1        0.9  \n",
       "42  binary:logistic  0.649803       1        0.9  \n",
       "12  binary:logistic  0.648361       1        0.9  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print grid_scores_\n",
    "grid_scores_to_df(clf_subsample.grid_scores_).sort_values('score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.684254212826\n",
      "{'colsample_bytree': 0.7, 'silent': 1, 'learning_rate': 0.05, 'n_estimators': 10000, 'subsample': 0.7, 'objective': 'binary:logistic', 'max_depth': 5}\n"
     ]
    }
   ],
   "source": [
    "print clf_subsample.best_score_\n",
    "print clf_subsample.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not much gains made here, I will scrap the subsampling in general and stick with clf\\_detailed. Let's make a prediction and see how it fared out in our songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict test\n",
    "y_test_pred = clf_detailed.predict(x_test)\n",
    "y_test_pred = [int(x) for x in y_test_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11b089450>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqEAAAH2CAYAAABAwVWMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11af59950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a new dataframe with just the song ids\n",
    "x_test_song_id_labels = my_itunes_data[my_itunes_data['song_id'].isin(test_song_ids)][['song_id', 'artist', 'title', 'genre']].reset_index(drop = True)\n",
    "\n",
    "# Append the predicted values to the song ids\n",
    "x_test_song_id_labels['y_test_pred'] = pd.Series(lb.inverse_transform(y_test_pred))\n",
    "\n",
    "# Group by and find the most commonly classified genre of each frame per song\n",
    "song_classification = x_test_song_id_labels.groupby(['song_id'])['y_test_pred'].agg(lambda x: x.value_counts().idxmax()).reset_index()\n",
    "\n",
    "# Plot histogram of predicted song genres\n",
    "song_classification['y_test_pred'].value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that's annoying. Somehow, it's guessing all rock now. How do the distribution of the predicted frames look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11af98c90>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArgAAAIxCAYAAACmf8s/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nACCKwAUAIIrABQAgisAFACDKB2xbVJsYcseoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1183a34d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_test_song_id_labels['y_test_pred'].value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the song themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>y_test_pred</th>\n",
       "      <th>song_id</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>Easy Listening</th>\n",
       "      <th>Rock</th>\n",
       "      <th>Easy Listening %</th>\n",
       "      <th>Rock %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1213</td>\n",
       "      <td>Fleetwood Mac</td>\n",
       "      <td>Dreams (Flight Facilities Remix)</td>\n",
       "      <td>Rock</td>\n",
       "      <td>50</td>\n",
       "      <td>596</td>\n",
       "      <td>0.077399</td>\n",
       "      <td>0.922601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1379</td>\n",
       "      <td>Green Day</td>\n",
       "      <td>Wake Me Up When September Ends</td>\n",
       "      <td>Rock</td>\n",
       "      <td>52</td>\n",
       "      <td>594</td>\n",
       "      <td>0.080495</td>\n",
       "      <td>0.919505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1667</td>\n",
       "      <td>Jewel</td>\n",
       "      <td>Foolish Games</td>\n",
       "      <td>Easy Listening</td>\n",
       "      <td>173</td>\n",
       "      <td>473</td>\n",
       "      <td>0.267802</td>\n",
       "      <td>0.732198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1742</td>\n",
       "      <td>Julie London</td>\n",
       "      <td>Cry Me A River</td>\n",
       "      <td>Easy Listening</td>\n",
       "      <td>237</td>\n",
       "      <td>409</td>\n",
       "      <td>0.366873</td>\n",
       "      <td>0.633127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1745</td>\n",
       "      <td>Julie London</td>\n",
       "      <td>I'm Glad There Is You</td>\n",
       "      <td>Easy Listening</td>\n",
       "      <td>217</td>\n",
       "      <td>429</td>\n",
       "      <td>0.335913</td>\n",
       "      <td>0.664087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1749</td>\n",
       "      <td>Julie London</td>\n",
       "      <td>It Never Entered My Mind</td>\n",
       "      <td>Easy Listening</td>\n",
       "      <td>287</td>\n",
       "      <td>359</td>\n",
       "      <td>0.444272</td>\n",
       "      <td>0.555728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1759</td>\n",
       "      <td>Julie London</td>\n",
       "      <td>Spring Is Here</td>\n",
       "      <td>Easy Listening</td>\n",
       "      <td>273</td>\n",
       "      <td>373</td>\n",
       "      <td>0.422601</td>\n",
       "      <td>0.577399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2420</td>\n",
       "      <td>Norah Jones</td>\n",
       "      <td>Happy Pills</td>\n",
       "      <td>Rock</td>\n",
       "      <td>150</td>\n",
       "      <td>496</td>\n",
       "      <td>0.232198</td>\n",
       "      <td>0.767802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2422</td>\n",
       "      <td>Norman Greenbaum</td>\n",
       "      <td>Spirit In The Sky</td>\n",
       "      <td>Rock</td>\n",
       "      <td>65</td>\n",
       "      <td>581</td>\n",
       "      <td>0.100619</td>\n",
       "      <td>0.899381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2519</td>\n",
       "      <td>Pink Floyd</td>\n",
       "      <td>Speak To Me - Breathe</td>\n",
       "      <td>Rock</td>\n",
       "      <td>50</td>\n",
       "      <td>596</td>\n",
       "      <td>0.077399</td>\n",
       "      <td>0.922601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2552</td>\n",
       "      <td>Pink Floyd</td>\n",
       "      <td>Nobody Home</td>\n",
       "      <td>Rock</td>\n",
       "      <td>76</td>\n",
       "      <td>570</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.882353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2556</td>\n",
       "      <td>Pink Floyd</td>\n",
       "      <td>Young Lust</td>\n",
       "      <td>Rock</td>\n",
       "      <td>27</td>\n",
       "      <td>619</td>\n",
       "      <td>0.041796</td>\n",
       "      <td>0.958204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2678</td>\n",
       "      <td>Red Hot Chili Peppers</td>\n",
       "      <td>Californication</td>\n",
       "      <td>Rock</td>\n",
       "      <td>35</td>\n",
       "      <td>611</td>\n",
       "      <td>0.054180</td>\n",
       "      <td>0.945820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2716</td>\n",
       "      <td>Robbie Williams &amp; Nicole Kidman</td>\n",
       "      <td>Something Stupid</td>\n",
       "      <td>Easy Listening</td>\n",
       "      <td>84</td>\n",
       "      <td>562</td>\n",
       "      <td>0.130031</td>\n",
       "      <td>0.869969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2842</td>\n",
       "      <td>Sam Smith</td>\n",
       "      <td>Stay With Me</td>\n",
       "      <td>Easy Listening</td>\n",
       "      <td>100</td>\n",
       "      <td>546</td>\n",
       "      <td>0.154799</td>\n",
       "      <td>0.845201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3002</td>\n",
       "      <td>Stacey Kent</td>\n",
       "      <td>Embraceable You</td>\n",
       "      <td>Easy Listening</td>\n",
       "      <td>255</td>\n",
       "      <td>391</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.605263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3003</td>\n",
       "      <td>Stacey Kent</td>\n",
       "      <td>If I Had You</td>\n",
       "      <td>Easy Listening</td>\n",
       "      <td>287</td>\n",
       "      <td>359</td>\n",
       "      <td>0.444272</td>\n",
       "      <td>0.555728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3031</td>\n",
       "      <td>Steve Miller Band</td>\n",
       "      <td>Wild Mountain Honey</td>\n",
       "      <td>Rock</td>\n",
       "      <td>31</td>\n",
       "      <td>615</td>\n",
       "      <td>0.047988</td>\n",
       "      <td>0.952012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3160</td>\n",
       "      <td>The Bee Gees</td>\n",
       "      <td>How Deep Is Your Love</td>\n",
       "      <td>Rock</td>\n",
       "      <td>86</td>\n",
       "      <td>560</td>\n",
       "      <td>0.133127</td>\n",
       "      <td>0.866873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3175</td>\n",
       "      <td>The Fray</td>\n",
       "      <td>How To Save A Life</td>\n",
       "      <td>Rock</td>\n",
       "      <td>12</td>\n",
       "      <td>634</td>\n",
       "      <td>0.018576</td>\n",
       "      <td>0.981424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3177</td>\n",
       "      <td>The Fray</td>\n",
       "      <td>You Found Me</td>\n",
       "      <td>Rock</td>\n",
       "      <td>33</td>\n",
       "      <td>613</td>\n",
       "      <td>0.051084</td>\n",
       "      <td>0.948916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3196</td>\n",
       "      <td>The Police</td>\n",
       "      <td>Voices Inside My Head (Ashley Beedle &amp; Dj Harv...</td>\n",
       "      <td>Rock</td>\n",
       "      <td>26</td>\n",
       "      <td>620</td>\n",
       "      <td>0.040248</td>\n",
       "      <td>0.959752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3329</td>\n",
       "      <td>U2</td>\n",
       "      <td>Sweetest Thing</td>\n",
       "      <td>Rock</td>\n",
       "      <td>29</td>\n",
       "      <td>617</td>\n",
       "      <td>0.044892</td>\n",
       "      <td>0.955108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3425</td>\n",
       "      <td>The Eagles</td>\n",
       "      <td>Hotel California</td>\n",
       "      <td>Rock</td>\n",
       "      <td>39</td>\n",
       "      <td>607</td>\n",
       "      <td>0.060372</td>\n",
       "      <td>0.939628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3818</td>\n",
       "      <td>Weezer</td>\n",
       "      <td>Say It Aint So</td>\n",
       "      <td>Rock</td>\n",
       "      <td>42</td>\n",
       "      <td>604</td>\n",
       "      <td>0.065015</td>\n",
       "      <td>0.934985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "y_test_pred  song_id                           artist  \\\n",
       "0               1213                    Fleetwood Mac   \n",
       "1               1379                        Green Day   \n",
       "2               1667   Jewel                            \n",
       "3               1742                     Julie London   \n",
       "4               1745                     Julie London   \n",
       "5               1749                     Julie London   \n",
       "6               1759                     Julie London   \n",
       "7               2420                      Norah Jones   \n",
       "8               2422                 Norman Greenbaum   \n",
       "9               2519                       Pink Floyd   \n",
       "10              2552                       Pink Floyd   \n",
       "11              2556                       Pink Floyd   \n",
       "12              2678            Red Hot Chili Peppers   \n",
       "13              2716  Robbie Williams & Nicole Kidman   \n",
       "14              2842                        Sam Smith   \n",
       "15              3002                      Stacey Kent   \n",
       "16              3003                      Stacey Kent   \n",
       "17              3031                Steve Miller Band   \n",
       "18              3160                     The Bee Gees   \n",
       "19              3175                         The Fray   \n",
       "20              3177                         The Fray   \n",
       "21              3196                       The Police   \n",
       "22              3329                               U2   \n",
       "23              3425                       The Eagles   \n",
       "24              3818                           Weezer   \n",
       "\n",
       "y_test_pred                                              title  \\\n",
       "0                             Dreams (Flight Facilities Remix)   \n",
       "1                               Wake Me Up When September Ends   \n",
       "2                               Foolish Games                    \n",
       "3                                               Cry Me A River   \n",
       "4                                        I'm Glad There Is You   \n",
       "5                                     It Never Entered My Mind   \n",
       "6                                               Spring Is Here   \n",
       "7                                                  Happy Pills   \n",
       "8                                            Spirit In The Sky   \n",
       "9                                        Speak To Me - Breathe   \n",
       "10                                                 Nobody Home   \n",
       "11                                                  Young Lust   \n",
       "12                                             Californication   \n",
       "13                                            Something Stupid   \n",
       "14                                                Stay With Me   \n",
       "15                                             Embraceable You   \n",
       "16                                                If I Had You   \n",
       "17                                         Wild Mountain Honey   \n",
       "18                                       How Deep Is Your Love   \n",
       "19                                          How To Save A Life   \n",
       "20                                                You Found Me   \n",
       "21           Voices Inside My Head (Ashley Beedle & Dj Harv...   \n",
       "22                                              Sweetest Thing   \n",
       "23                                            Hotel California   \n",
       "24                                              Say It Aint So   \n",
       "\n",
       "y_test_pred           genre  Easy Listening  Rock  Easy Listening %    Rock %  \n",
       "0                      Rock              50   596          0.077399  0.922601  \n",
       "1                      Rock              52   594          0.080495  0.919505  \n",
       "2            Easy Listening             173   473          0.267802  0.732198  \n",
       "3            Easy Listening             237   409          0.366873  0.633127  \n",
       "4            Easy Listening             217   429          0.335913  0.664087  \n",
       "5            Easy Listening             287   359          0.444272  0.555728  \n",
       "6            Easy Listening             273   373          0.422601  0.577399  \n",
       "7                      Rock             150   496          0.232198  0.767802  \n",
       "8                      Rock              65   581          0.100619  0.899381  \n",
       "9                      Rock              50   596          0.077399  0.922601  \n",
       "10                     Rock              76   570          0.117647  0.882353  \n",
       "11                     Rock              27   619          0.041796  0.958204  \n",
       "12                     Rock              35   611          0.054180  0.945820  \n",
       "13           Easy Listening              84   562          0.130031  0.869969  \n",
       "14           Easy Listening             100   546          0.154799  0.845201  \n",
       "15           Easy Listening             255   391          0.394737  0.605263  \n",
       "16           Easy Listening             287   359          0.444272  0.555728  \n",
       "17                     Rock              31   615          0.047988  0.952012  \n",
       "18                     Rock              86   560          0.133127  0.866873  \n",
       "19                     Rock              12   634          0.018576  0.981424  \n",
       "20                     Rock              33   613          0.051084  0.948916  \n",
       "21                     Rock              26   620          0.040248  0.959752  \n",
       "22                     Rock              29   617          0.044892  0.955108  \n",
       "23                     Rock              39   607          0.060372  0.939628  \n",
       "24                     Rock              42   604          0.065015  0.934985  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add counter for counting frames\n",
    "x_test_song_id_labels['counter'] = 1\n",
    "\n",
    "# Find the percentage of frames that were classified as Rock and Easy Listening in each song\n",
    "y_pred_song_table = pd.pivot_table(x_test_song_id_labels, values = 'counter', index = ['song_id', 'artist', 'title', 'genre'], columns = ['y_test_pred'], aggfunc = np.sum).reset_index()\n",
    "\n",
    "# Calculate percentages of frames\n",
    "total_frames = 646\n",
    "y_pred_song_table['Easy Listening %'] = y_pred_song_table['Easy Listening'] / 646\n",
    "y_pred_song_table['Rock %'] = y_pred_song_table['Rock'] / 646\n",
    "\n",
    "# Show table\n",
    "y_pred_song_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1167c6950>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArwAAAHlCAYAAAAX0y/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e6e3c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_song_table[['Easy Listening %']].plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we're looking at the distribution of songs that are classified as Easy Listening as a percentage. There is that gap right at 0.25 where we could probably make the split. Let's see what happens if we\n",
    "- Classify anything _**greater than or equal to 25% Easy Listening %**_ as Easy Listening\n",
    "- Classify anything _**less than 25% Easy Listening %**_ as Rock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Perform manual classification\n",
    "y_pred_song_table['y_test_pred_label'] = np.where(\n",
    "    y_pred_song_table['Easy Listening %'] >= 0.25,\n",
    "    'Easy Listening',\n",
    "    'Rock'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7,  2],\n",
       "       [ 0, 16]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print confusion matrix\n",
    "confusion_matrix(y_pred_song_table['genre'], y_pred_song_table['y_test_pred_label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red; font-size: 3em;\">**Holy cow, it got 23 / 25 songs!!!!!!!!!!!!!!!!!**</span>\n",
    "\n",
    "![](https://i.giphy.com/media/xeXEpUVvAxCV2/giphy.webp)\n",
    "\n",
    "Let's look at the songs it didn't get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>y_test_pred</th>\n",
       "      <th>song_id</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>Easy Listening</th>\n",
       "      <th>Rock</th>\n",
       "      <th>Easy Listening %</th>\n",
       "      <th>Rock %</th>\n",
       "      <th>y_test_pred_label</th>\n",
       "      <th>prediction_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2716</td>\n",
       "      <td>Robbie Williams &amp; Nicole Kidman</td>\n",
       "      <td>Something Stupid</td>\n",
       "      <td>Easy Listening</td>\n",
       "      <td>84</td>\n",
       "      <td>562</td>\n",
       "      <td>0.130031</td>\n",
       "      <td>0.869969</td>\n",
       "      <td>Rock</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2842</td>\n",
       "      <td>Sam Smith</td>\n",
       "      <td>Stay With Me</td>\n",
       "      <td>Easy Listening</td>\n",
       "      <td>100</td>\n",
       "      <td>546</td>\n",
       "      <td>0.154799</td>\n",
       "      <td>0.845201</td>\n",
       "      <td>Rock</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "y_test_pred  song_id                           artist             title  \\\n",
       "13              2716  Robbie Williams & Nicole Kidman  Something Stupid   \n",
       "14              2842                        Sam Smith      Stay With Me   \n",
       "\n",
       "y_test_pred           genre  Easy Listening  Rock  Easy Listening %    Rock %  \\\n",
       "13           Easy Listening              84   562          0.130031  0.869969   \n",
       "14           Easy Listening             100   546          0.154799  0.845201   \n",
       "\n",
       "y_test_pred y_test_pred_label prediction_correct  \n",
       "13                       Rock              False  \n",
       "14                       Rock              False  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate whether or not the prediction was correct\n",
    "y_pred_song_table['prediction_correct'] = np.where(\n",
    "    y_pred_song_table['genre'] == y_pred_song_table['y_test_pred_label'],\n",
    "    True,\n",
    "    False\n",
    ")\n",
    "\n",
    "# Show songs incorrectly predicted\n",
    "y_pred_song_table[y_pred_song_table['prediction_correct'] == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, I'm not quite sure why \"Something Stupid\" was classified as Rock, but I can see how \"Stay With Me\" could be. It's got a heavier drums whereas some songs I classified as Easy Listening have no percussion whatsoever. This is a pretty good example of how my categorizations could've gone either way!\n",
    "\n",
    "[![IMAGE ALT TEXT](http://img.youtube.com/vi/pB-5XG-DbAA/0.jpg)](http://www.youtube.com/watch?v=pB-5XG-DbAA \"Video Title\")\n",
    "\n",
    "Looking back, I should have probably classified this as pop... but hey... I was literally trying to get through each song within 5 seconds so I'd have the rest of my life back to actually build the model.\n",
    "\n",
    "Overall, I'm extremely happy with how this turned out. For what I wanted to get out of this project, this was awesome. I came in not even knowing how to think about a song, and now I've had _**some**_ moderate success even being able to classify songs with diverse genres. I'm not trying to build a startup or sell a product or anything, so I'm not looking for 100% accuracy. Just developing that train of thought and understanding how to break down this type of problem is what I'm interested in, and I think I've gotten 80% there. Of course, that last 20% is what will build the real product and what people go to school for. I'm just a lowly naive generalist who's just looking to scratch the surface for now.\n",
    "\n",
    "I kind of also want to try a neural network out for fun. There's a ton of talk around [Tensorflow](https://www.tensorflow.org/) these days... Shall we?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
