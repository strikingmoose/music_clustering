{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 - Gradient Boosting (Part II)\n",
    "## Troubleshooting Our Model\n",
    "So we saw that our first GBT approach in the last post was, to quote myself, a \"steaming pile of hot garbage\". In reality, that's probably and understatement because it's barely even a model. I could've gotten the results with literally no model and straight guesses. Disappointing to say the least.\n",
    "\n",
    "![](http://i.imgur.com/8zXjYXy.gif)\n",
    "\n",
    "Of course, now, the question is... Why? Why is this model so bad? There are so many things that could have gone wrong:\n",
    "1. Did I misclassify some songs in my library in theory?\n",
    "2. Did I misclassify some songs in my library in practice (i.e. accidentally classified a Rock song as R&B)?\n",
    "3. Is my feature extraction method appropriate (i.e. MFCCs)?\n",
    "4. Is gradient boosting appropriate for this application?\n",
    "5. Did I take enough gradient boosting iterations to really allow the model settle and optimize?\n",
    "\n",
    "So many questions. So little answers... The solutions to the above would be\n",
    "1. Re-think my classifications of genres and re-classify my entire library, this may include adding new genres, taking away existing genres, or switching songs from one genre to another.\n",
    "2. Thoroughly check all 4000 songs again for mistakes.\n",
    "3. Do another week of research regarding feature extraction methods for music.\n",
    "4. Try other models (neural network).\n",
    "5. Leave the model running overnight / get a faster CPU (AWS?).\n",
    "\n",
    "I'm going to try to tweak \\#1 purely on the basis that it's probably the least time consuming solution... a quick win _**IF**_ it works, and not too big of a sunk cost if it doesn't. I'm actually going to approach \\#1 in a way that should mitigate the effects of \\#2, \\#3, and \\#5 as well. I'm going to take two very distinct genres of equal population and try to run the model only on those 2. Let's take Rock and Easy Listening for now because they should be quite different (the Radioheads and Portisheads come to mind that could _**kind of**_ cross over semetimes, but for the most part they're quite different).\n",
    "\n",
    "With only these two genres, we're dealing with less than 10% of our original data set. We're also taking the more ambiguous genres out (e.g. Dance, R&B, Hip Hop and Jazz have more overlap than Rock and Easy Listening). With this, I'll get more confidence in whether or not MFCCs do the job as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Enable plots in the notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Seaborn makes our plots prettier\n",
    "import seaborn\n",
    "seaborn.set(style = 'ticks')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the dataset we generated in the previous post\n",
    "my_itunes_data = pd.read_csv(\n",
    "    '../features.csv', \n",
    "    header = None,\n",
    "    names = [\n",
    "        'song_id',\n",
    "        'title',\n",
    "        'artist',\n",
    "        'genre',\n",
    "        'mfcc_1',\n",
    "        'mfcc_2',\n",
    "        'mfcc_3',\n",
    "        'mfcc_4',\n",
    "        'mfcc_5',\n",
    "        'mfcc_6',\n",
    "        'mfcc_7',\n",
    "        'mfcc_8',\n",
    "        'mfcc_9',\n",
    "        'mfcc_10'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "song_id      int64\n",
       "title       object\n",
       "artist      object\n",
       "genre       object\n",
       "mfcc_1     float64\n",
       "mfcc_2     float64\n",
       "mfcc_3     float64\n",
       "mfcc_4     float64\n",
       "mfcc_5     float64\n",
       "mfcc_6     float64\n",
       "mfcc_7     float64\n",
       "mfcc_8     float64\n",
       "mfcc_9     float64\n",
       "mfcc_10    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that the data imported properly\n",
    "my_itunes_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2470678"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check number of rows in the data set\n",
    "my_itunes_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3825"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of songs\n",
    "my_itunes_data['song_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove any training samples with \"Prince\" as artist\n",
    "my_itunes_data = my_itunes_data[(my_itunes_data['genre'].isin(['Rock', 'Easy Listening']))]\n",
    "\n",
    "# Check the number of songs\n",
    "my_itunes_data['song_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're dealing with wayyyyy less songs now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x119330610>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqkAAAIxCAYAAABuEyHpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAKBw/i+X9iFywWhZ5QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119330d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aggregate data to song level to see how many songs are of each genre\n",
    "my_itunes_data[['song_id', 'genre']].drop_duplicates()['genre'].value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got about twice the number of Rock songs than Easy Listening, but should be fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 183 songs in the training set and 25 songs in the test set\n"
     ]
    }
   ],
   "source": [
    "# Get the list of unique song_id's\n",
    "unique_song_ids = my_itunes_data['song_id'].unique()\n",
    "\n",
    "# Get ~10% of the test data\n",
    "test_song_ids = random.sample(unique_song_ids, 25)\n",
    "\n",
    "# All other songs become the training set\n",
    "train_song_ids = [x for x in unique_song_ids if x not in test_song_ids]\n",
    "\n",
    "print 'There are {} songs in the training set and {} songs in the test set'.format(len(train_song_ids), len(test_song_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1192e0110>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqEAAAIxCAYAAAB9xGEdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114f76cd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the distribution of genres in the test set to ensure the sample is not completely lop-sided\n",
    "my_itunes_data[my_itunes_data['song_id'].isin(test_song_ids)][['song_id', 'genre']].drop_duplicates()['genre'].value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking good. Let's train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 118218 training samples\n",
      "There are 16150 test samples\n"
     ]
    }
   ],
   "source": [
    "# Build training set\n",
    "x_train = my_itunes_data[my_itunes_data['song_id'].isin(train_song_ids)].filter(regex = 'mfcc.*').values\n",
    "y_train = my_itunes_data[my_itunes_data['song_id'].isin(train_song_ids)][['genre']].values.T[0]\n",
    "print 'There are {} training samples'.format(len(x_train))\n",
    "\n",
    "# Build test set\n",
    "x_test = my_itunes_data[my_itunes_data['song_id'].isin(test_song_ids)].filter(regex = 'mfcc.*').values\n",
    "y_test = my_itunes_data[my_itunes_data['song_id'].isin(test_song_ids)][['genre']].values.T[0]\n",
    "print 'There are {} test samples'.format(len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import xgboost\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y (train) set has the following labels [0 1] and has 118218 elements\n",
      "Y (test) set has the following labels [0 1] and has 16150 elements\n"
     ]
    }
   ],
   "source": [
    "# Encode our labels to integers (e.g. \"Dance\" becomes a number like 1 or 2)\n",
    "lb = LabelEncoder()\n",
    "y_train_encoded = lb.fit_transform(y_train)\n",
    "y_test_encoded = lb.transform(y_test)\n",
    "print 'Y (train) set has the following labels {} and has {} elements'.format(np.unique(y_train_encoded), len(y_train_encoded))\n",
    "print 'Y (test) set has the following labels {} and has {} elements'.format(np.unique(y_test_encoded), len(y_test_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fit our train and test data to a xgb sparse matrix\n",
    "xgb_train = xgb.DMatrix(x_train, label = y_train_encoded)\n",
    "xgb_test = xgb.DMatrix(x_test, label = y_test_encoded)\n",
    "xgb_test_no_label = xgb.DMatrix(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set xgboost parameters\n",
    "param = {\n",
    "    'max_depth': 1,\n",
    "    'nthread': 2,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'silent': 1\n",
    "}\n",
    "\n",
    "num_rounds = 10000\n",
    "\n",
    "eval_list  = [(xgb_train, 'train'), (xgb_test, 'eval')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This great. We can train our model MUCH faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train model\n",
    "bst = xgb.train(param, xgb_train, num_rounds, eval_list, early_stopping_rounds = 250, verbose_eval = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model was on iteration 176 with a score of 0.549914\n"
     ]
    }
   ],
   "source": [
    "# Define a function to output best model info\n",
    "def best_model_info(bst):\n",
    "    print 'The best model was on iteration {} with a score of {}'.format(bst.best_iteration, bst.best_score)\n",
    "    \n",
    "# View best model info from last train\n",
    "best_model_info(bst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we only have 2 classes for this example, we can actually use xgboost to evaluate the AUC rather than straight classification error. AUC will give us a better sense of how well the model is able to separate out sensitivity and specificity of the classes. Because each iteration of xgboost is so fast here, I can also just set the maximum number of rounds to something crazy like 10,000 and set the early_stopping_rounds parameter as well. As we saw in the R implementation, early_stopping_rounds simply allows us to run the model into oblivion and xgboost itself will automatically stop when the evaluation metric doesn't get better for, as we've set here, 250 iterations. Here, I turned 'silent': 1 in the model params verbose_eval = False in the train command to surpess the information because the bst parameter should give us all the information we need without needing to see every iteration's information.\n",
    "\n",
    "Since our model is training so fast, we can tweak a few parameters... one that I've been ignoring is the eta parameter which controls the learning rate. The xgboost default is 0.3 which isn't that big, but we can decrease it even more because time we have time to spare with the model training so quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tweak eta parameter\n",
    "param_eta_01 = param\n",
    "param_eta_01['eta'] = 0.1\n",
    "\n",
    "# Train model\n",
    "bst_eta_01 = xgb.train(param, xgb_train, num_rounds, eval_list, early_stopping_rounds = 250, verbose_eval = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model was on iteration 1558 with a score of 0.54947\n"
     ]
    }
   ],
   "source": [
    "# View best model info from last train\n",
    "best_model_info(bst_eta_01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're not doing much better here. I doubt things would change if we slowed it down even more but..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tweak eta parameter\n",
    "param_eta_005 = param\n",
    "param_eta_005['eta'] = 0.05\n",
    "\n",
    "# Train model\n",
    "bst_eta_005 = xgb.train(param, xgb_train, num_rounds, eval_list, early_stopping_rounds = 250, verbose_eval = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model was on iteration 768 with a score of 0.548409\n"
     ]
    }
   ],
   "source": [
    "# View best model info from last train\n",
    "best_model_info(bst_eta_005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, it actually took less iterations to train at a learning rate of 0.05 than at 0.1. I can maybe attribute that to the luck of the draw in that the 0.1 step size may have just made a few splits that prolonged the training process, where 0.05 was able to get to the point a bit faster. Regardless, we se a similar AUC, and it's not good.\n",
    "\n",
    "![](https://media.giphy.com/media/yisc7FaqoEfjG/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I just want to take a bit of a deeper dive to see which songs were classified what just to see if I can find out a bit more information that way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict test\n",
    "y_test_pred = bst_eta_005.predict(xgb_test_no_label, ntree_limit = bst_eta_005.best_ntree_limit)\n",
    "y_test_pred = [int(x) for x in y_test_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x117482390>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqEAAAIxCAYAAAB9xGEdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niVAAANKJUAAA0olQAADS/X86LypN8SuAIAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1150eb410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a new dataframe with just the song ids\n",
    "x_test_song_id_labels = my_itunes_data[my_itunes_data['song_id'].isin(test_song_ids)][['song_id']].reset_index(drop = True)\n",
    "\n",
    "# Append the predicted values to the song ids\n",
    "x_test_song_id_labels['y_test_pred'] = pd.Series(lb.inverse_transform(y_test_pred))\n",
    "\n",
    "# Group by and find the most commonly classified genre of each frame per song\n",
    "song_classification = x_test_song_id_labels.groupby(['song_id'])['y_test_pred'].agg(lambda x: x.value_counts().idxmax()).reset_index()\n",
    "\n",
    "# Plot histogram of predicted song genres\n",
    "song_classification['y_test_pred'].value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh wow, that's quite unexpected... it thinks everything is easy listening. Okay then. This doesn't quite solve any of the problems I had haha... probably just creates more to be honest. There is still a chance that my music classification is wrong, and there is still a chance that I'm extracting MFCCs wrong or that MFCCs are a wrong way to approach the problem in general. There is one _**last**_ thing I can try to tweak in the xgboost model, and that's the depth of the trees. I don't expect much of a difference, but let's give it a shot. Since we're playing around with multiple parameters here, I'm actually going to try the GridSearchCV function from sklearn.\n",
    "\n",
    "The GridSearchCV essentially allows us to\n",
    "1. Perform cross validation (which we had not been doing before, we were only using a single train test split)\n",
    "2. Loop through multiple parameters efficiently\n",
    "\n",
    "I have to caveat this right now by saying that _**MY METHOD OF CV RIGHT NOW MAY BE INACCURATE**_. Cross validation helps decrease the out-of-sample error by splitting our data up into multiple folds and training and testing multiple times. For example, for 5-fold cross validation, each iteration would look something like this:\n",
    "\n",
    "![](http://tomaszkacmajor.pl/wp-content/uploads/2016/05/cross-validation.png)\n",
    "\n",
    "Notice that each set is split up into 1 parts, and in each iteration, 4 of them are used as training and 1 of them is used as the test. The reason I wasn't using CV before, and only train test split, was because each of my training samples are _**frames of songs**_, not the _**actual songs themselves**_. Because they are frames, I may be training on parts of one song, and testing on other parts. Although, in theory, each sample is individual from each other, the logic in the context we're working in (music and songs) says we should be training and testing on _**songs**_ themselves.\n",
    "\n",
    "For me to run cross validation, let alone cross validation over a grid of parameters like GridSearchCV does, I'd have to write custom code (like I did with the train test split method) to not just randomly take 20% of my sample, but 20% of my sample _**in terms of songs**_, which ends up being 20% of the overall samples in general because I took the same amount of samples per song. I should never be training on 50% of one song and testing on 50% of another song.\n",
    "\n",
    "But with that entire rant, I'm going to go ahead and actually do exactly that because my objective here is just to scratch the surface on if parameters make a big difference, not do a deep dive. This should give me enough of an idea because I think I should still see a bump in accuracy.\n",
    "\n",
    "To learn how GridSearchCV works with xgboost, I'm referring to [this kaggle page](https://www.kaggle.com/phunter/xgboost-with-gridsearchcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "xgb_model_test = xgb.XGBClassifier()\n",
    "\n",
    "# Set parameters (for GridSearchCV, every value must be in a list, even if there is only 1 value we want to test)\n",
    "param_grid_search_test = {\n",
    "#     'max_depth': [1, 5, 10],\n",
    "#     'learning_rate': [0.05, 0.1, 0.5, 1, 2],\n",
    "    'max_depth': [1],\n",
    "    'objective': ['binary:logistic'],\n",
    "    'silent': [1],\n",
    "#     'n_estimators': 1000\n",
    "    'n_estimators': [200]\n",
    "}\n",
    "\n",
    "# Set up grid search\n",
    "clf_test = GridSearchCV(\n",
    "    xgb_model_test, \n",
    "    param_grid_search_test, \n",
    "    n_jobs = -1, \n",
    "    cv = 5, \n",
    "    scoring = 'roc_auc',\n",
    "    verbose = 1, \n",
    "    refit = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   32.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'objective': ['binary:logistic'], 'n_estimators': [200], 'max_depth': [1], 'silent': [1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Suppress warnings because I'm getting a deprecation warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Fit model\n",
    "clf_test.fit(x_train, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.540156962394\n",
      "{'n_estimators': 200, 'objective': 'binary:logistic', 'max_depth': 1, 'silent': 1}\n"
     ]
    }
   ],
   "source": [
    "print clf_test.best_score_\n",
    "print clf_test.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I just tried a test run above, and I've gotten the model to train! Hurrah! You'll see that my parameters list contains some commented out values of parameters that I actually want to train, but I just wanted to do a test run first because I could be waiting a while if something went wrong. Training 5 models (1 model with 5 CV) took about 45 seconds here, so not bad!\n",
    "\n",
    "I'm going to extend this training process, first of all, by using 1000 iterations instead of 200. I'm then going to add 12x more models (3 max_depth values and 4 eta values), in certain cases using larger tree depths, and using slower learning rates as well. Let's try it anyways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "\n",
    "# Set parameters (for GridSearchCV, every value must be in a list, even if there is only 1 value we want to test)\n",
    "param_grid_search = {\n",
    "    'max_depth': [1, 5, 10],\n",
    "    'learning_rate': [0.05, 0.1, 0.5, 1, 2],\n",
    "    'objective': ['binary:logistic'],\n",
    "    'silent': [1],\n",
    "    'n_estimators': [1000]\n",
    "}\n",
    "\n",
    "# Set up grid search\n",
    "clf = GridSearchCV(\n",
    "    xgb_model, \n",
    "    param_grid_search, \n",
    "    n_jobs = -1, \n",
    "    cv = 5, \n",
    "    scoring = 'roc_auc',\n",
    "    verbose = 2, \n",
    "    refit = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=1, silent=1 \n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=1, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=1, silent=1 -  48.5s\n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=1, silent=1 -  48.9s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=1, silent=1 \n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=1, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=1, silent=1 -  46.5s\n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=1, silent=1 -  46.5s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=1, silent=1 \n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=5, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=1, silent=1 -  46.0s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=5, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=5, silent=1 - 3.5min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=5, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=5, silent=1 - 3.5min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=5, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=5, silent=1 - 3.5min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=5, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=5, silent=1 - 3.5min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=5, silent=1 -123.2min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=10, silent=1 -425.5min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=10, silent=1 -305.8min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=10, silent=1 - 8.1min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=10, silent=1 - 8.2min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=1, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=1, silent=1 -  45.7s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=1, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=1, silent=1 -  45.9s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=1, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=1, silent=1 -  46.0s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=1, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=1, silent=1 -  46.5s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=1, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=1, silent=1 -  45.7s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=5, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.05, max_depth=10, silent=1 - 7.4min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=5, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=5, silent=1 - 3.5min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=5, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=5, silent=1 - 3.5min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=5, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=5, silent=1 - 3.5min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=5, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=5, silent=1 - 3.5min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=5, silent=1 - 3.5min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=10, silent=1 - 7.3min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=10, silent=1 - 7.3min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=10, silent=1 - 7.3min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=10, silent=1 - 7.3min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=1, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=1, silent=1 -  45.6s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=1, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=1, silent=1 -  45.8s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=1, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=1, silent=1 -  49.4s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=1, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=1, silent=1 -  45.6s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=1, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=1, silent=1 -  45.9s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=5, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.1, max_depth=10, silent=1 - 7.4min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=5, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=5, silent=1 - 4.8min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=5, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=5, silent=1 - 5.2min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=5, silent=1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed: 484.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=5, silent=1 - 5.5min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=5, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=5, silent=1 - 5.1min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=5, silent=1 - 3.5min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=10, silent=1 - 7.3min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=10, silent=1 - 7.3min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=10, silent=1 - 7.3min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=10, silent=1 - 7.3min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=1, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=1, silent=1 -  45.6s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=1, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=1, silent=1 -  45.5s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=1, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=1, silent=1 -  45.6s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=1, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=1, silent=1 -  46.1s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=1, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=1, silent=1 -  45.5s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=5, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=0.5, max_depth=10, silent=1 - 7.3min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=5, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=5, silent=1 - 3.5min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=5, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=5, silent=1 - 3.5min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=5, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=5, silent=1 - 3.8min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=5, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=5, silent=1 - 3.8min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=5, silent=1 - 3.8min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=10, silent=1 - 7.3min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=10, silent=1 - 7.6min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=10, silent=1 - 8.4min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=10, silent=1 - 8.9min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=1, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=1, silent=1 -  29.7s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=1, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=1, silent=1 -  28.1s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=1, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=1, silent=1 -  28.7s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=1, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=1, silent=1 -  25.5s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=1, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=1, silent=1 -  27.8s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=5, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=5, silent=1 -  35.9s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=5, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=5, silent=1 -  31.7s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=5, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=5, silent=1 -  35.4s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=5, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=1, max_depth=10, silent=1 - 8.3min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=5, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=5, silent=1 -  34.9s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=5, silent=1 -  38.2s\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=10, silent=1 - 5.3min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=10, silent=1 - 5.4min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=10, silent=1 - 4.1min\n",
      "[CV] n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=10, silent=1 \n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=10, silent=1 - 4.1min\n",
      "[CV]  n_estimators=1000, objective=binary:logistic, learning_rate=2, max_depth=10, silent=1 - 3.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  75 out of  75 | elapsed: 556.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'objective': ['binary:logistic'], 'n_estimators': [1000], 'learning_rate': [0.05, 0.1, 0.5, 1, 2], 'max_depth': [1, 5, 10], 'silent': [1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "clf.fit(x_train, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.687249669247\n",
      "{'n_estimators': 1000, 'objective': 'binary:logistic', 'learning_rate': 0.05, 'max_depth': 5, 'silent': 1}\n"
     ]
    }
   ],
   "source": [
    "print clf.best_score_\n",
    "print clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, that actually made quite a difference. We see with a slower learning rate and more depth in our trees, we've gained ~15% more area under our ROC curve! That's awesome. At the risk of sounding like an addict, I must go deeper here.\n",
    "\n",
    "<img src=\"http://i0.kym-cdn.com/photos/images/facebook/000/531/557/a88.jpg\" width=\"400\" />\n",
    "\n",
    "Let me re-run the model with even more fine-tuned learning rates and max\\_depths. I also bumped the number of rounds up to 10,000 becauwe we are using _**much smaller step sizes**_ (learning rates / etas). I've also just found out that you can implement xgboost early stopping in conjunction with GridSearchCV as well... life just keeps getting better... goodness gracious. One caveat of this is that, when we implmented early stopping before, we had a consistent training set and a consistent test set. This made sense because, while our training error keeps decreasing, our test error is what our early stopping measured on. If the test error doesn't improve in however many specified iterations, we stop the process altogether because it looks like we've found a minimum in test error. When we're doing cross validation, _**our training set is always changing**_. There exists a chance that our randomly defined training set actually overlaps with our test set specified for early stopping, and that the test error will keep decreasing with the CV train error. Our training set created by CV, however, takes up 80% of our data because we're using 5-fold CV, and our early stopping test set takes up 10% of our data because I've defined that number at the top of the script, so already our two data sets _**overlap directly, even by pure chance**_, but I won't pretend like there doesn't exist any possibility of correlation here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "xgb_model_detailed = xgb.XGBClassifier()\n",
    "\n",
    "# Set parameters (for GridSearchCV, every value must be in a list, even if there is only 1 value we want to test)\n",
    "param_detailed = {\n",
    "    'max_depth': [3, 4, 5, 6, 7],\n",
    "    'learning_rate': [0.01, 0.02, 0.03, 0.04, 0.05],\n",
    "    'objective': ['binary:logistic'],\n",
    "    'silent': [1],\n",
    "    'n_estimators': [10000]\n",
    "}\n",
    "\n",
    "fit_params_detailed = {\n",
    "    'early_stopping_rounds': 300,\n",
    "    'eval_metric': 'auc',\n",
    "    'eval_set': [[x_test, y_test_encoded]],\n",
    "    'verbose': True\n",
    "}\n",
    "\n",
    "# Set up grid search\n",
    "clf_detailed = GridSearchCV(\n",
    "    xgb_model_detailed,\n",
    "    param_detailed,\n",
    "    fit_params = fit_params_detailed,\n",
    "    n_jobs = 1,\n",
    "    cv = 5, \n",
    "    scoring = 'roc_auc',\n",
    "    verbose = 2,\n",
    "    refit = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV] n_estimators=10000, objective=binary:logistic, learning_rate=0.01, max_depth=3, silent=1 \n",
      "[0]\tvalidation_0-auc:0.534366\n",
      "Will train until validation_0-auc hasn't improved in 300 rounds.\n",
      "[1]\tvalidation_0-auc:0.534366\n",
      "[2]\tvalidation_0-auc:0.534366\n",
      "[3]\tvalidation_0-auc:0.534366\n",
      "[4]\tvalidation_0-auc:0.534366\n",
      "[5]\tvalidation_0-auc:0.534367\n",
      "[6]\tvalidation_0-auc:0.534367\n",
      "[7]\tvalidation_0-auc:0.534367\n",
      "[8]\tvalidation_0-auc:0.534367\n",
      "[9]\tvalidation_0-auc:0.534367\n",
      "[10]\tvalidation_0-auc:0.534367\n",
      "[11]\tvalidation_0-auc:0.532794\n",
      "[12]\tvalidation_0-auc:0.529813\n",
      "[13]\tvalidation_0-auc:0.534232\n",
      "[14]\tvalidation_0-auc:0.535678\n",
      "[15]\tvalidation_0-auc:0.535674\n",
      "[16]\tvalidation_0-auc:0.535578\n",
      "[17]\tvalidation_0-auc:0.535913\n",
      "[18]\tvalidation_0-auc:0.533292\n",
      "[19]\tvalidation_0-auc:0.533763\n",
      "[20]\tvalidation_0-auc:0.535231\n",
      "[21]\tvalidation_0-auc:0.535632\n",
      "[22]\tvalidation_0-auc:0.538371\n",
      "[23]\tvalidation_0-auc:0.537885\n",
      "[24]\tvalidation_0-auc:0.538633\n",
      "[25]\tvalidation_0-auc:0.53912\n",
      "[26]\tvalidation_0-auc:0.536671\n",
      "[27]\tvalidation_0-auc:0.543912\n",
      "[28]\tvalidation_0-auc:0.544754\n",
      "[29]\tvalidation_0-auc:0.544584\n",
      "[30]\tvalidation_0-auc:0.546194\n",
      "[31]\tvalidation_0-auc:0.546099\n",
      "[32]\tvalidation_0-auc:0.546483\n",
      "[33]\tvalidation_0-auc:0.546021\n",
      "[34]\tvalidation_0-auc:0.546307\n",
      "[35]\tvalidation_0-auc:0.546322\n",
      "[36]\tvalidation_0-auc:0.547264\n",
      "[37]\tvalidation_0-auc:0.547159\n",
      "[38]\tvalidation_0-auc:0.546909\n",
      "[39]\tvalidation_0-auc:0.547252\n",
      "[40]\tvalidation_0-auc:0.548174\n",
      "[41]\tvalidation_0-auc:0.547757\n",
      "[42]\tvalidation_0-auc:0.547338\n",
      "[43]\tvalidation_0-auc:0.547909\n",
      "[44]\tvalidation_0-auc:0.547949\n",
      "[45]\tvalidation_0-auc:0.547868\n"
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "clf_detailed.fit(x_train, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
